{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn7zk14x7K5C"
      },
      "source": [
        "# **fMRI Learning Stage Classification with Vision Transformers**\n",
        "\n",
        "This notebook implements a Vision Transformer model to classify different stages of learning from fMRI data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGf0np537K5D"
      },
      "source": [
        "## Setup and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "vvZ2HYx-7K5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b2ee3b-87d3-445f-e1a8-2d13b67058a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lru-dict in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pywavelets in /usr/local/lib/python3.10/dist-packages (1.7.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (5.3.2)\n",
            "Requirement already satisfied: openneuro-py in /usr/local/lib/python3.10/dist-packages (2024.2.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (1.35.72)\n",
            "Requirement already satisfied: nilearn in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from pywavelets) (1.26.4)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.10/dist-packages (from nibabel) (6.4.5)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from nibabel) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from nibabel) (4.12.2)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.10/dist-packages (from openneuro-py) (24.1.0)\n",
            "Requirement already satisfied: httpx>=0.15 in /usr/local/lib/python3.10/dist-packages (from openneuro-py) (0.27.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from openneuro-py) (4.3.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openneuro-py) (2.32.3)\n",
            "Requirement already satisfied: sgqlc in /usr/local/lib/python3.10/dist-packages (from openneuro-py) (16.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openneuro-py) (4.66.6)\n",
            "Requirement already satisfied: typer[all] in /usr/local/lib/python3.10/dist-packages (from openneuro-py) (0.13.0)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.72 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.35.72)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3) (0.10.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.4.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nilearn) (5.3.0)\n",
            "Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.72->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.72->boto3) (2.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.15->openneuro-py) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.15->openneuro-py) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.15->openneuro-py) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.15->openneuro-py) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.15->openneuro-py) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.15->openneuro-py) (0.14.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.2.0->nilearn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.2.0->nilearn) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openneuro-py) (3.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.0->nilearn) (3.5.0)\n",
            "Requirement already satisfied: graphql-core<4.0.0,>=3.2.4 in /usr/local/lib/python3.10/dist-packages (from sgqlc->openneuro-py) (3.2.5)\n",
            "\u001b[33mWARNING: typer 0.13.0 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]->openneuro-py) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]->openneuro-py) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]->openneuro-py) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.72->boto3) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer[all]->openneuro-py) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer[all]->openneuro-py) (2.18.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.15->openneuro-py) (1.2.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer[all]->openneuro-py) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install lru-dict pywavelets nibabel openneuro-py boto3 nilearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahV3D1YA7K5D"
      },
      "source": [
        "#### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "2Tr56np47K5D"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import json\n",
        "import logging\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tarfile\n",
        "import pywt\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import nilearn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from einops import rearrange\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from timm.models.layers import DropPath\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from dataclasses import dataclass, field\n",
        "from functools import partial\n",
        "from collections import defaultdict\n",
        "from torch.optim.swa_utils import AveragedModel, SWALR\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from scipy.ndimage import zoom\n",
        "from scipy import signal\n",
        "from scipy.interpolate import interp1d\n",
        "from einops.layers.torch import Rearrange\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "from lru import LRU as LRUCache\n",
        "from torch.optim import AdamW\n",
        "from openneuro import download\n",
        "import boto3\n",
        "from pywt import wavedec\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from lru import LRU\n",
        "from itertools import chain\n",
        "from nilearn import plotting, image\n",
        "from scipy import stats\n",
        "import torch.utils.checkpoint as checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44WF76hY7K5D"
      },
      "source": [
        "#### System Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "lC56vmTl7K5E"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq4estSg7K5E"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "NRTgHOd47K5E"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    # paths (unchanged)\n",
        "    ROOT: str = \"/content/drive/MyDrive/learnedSpectrum\"\n",
        "    CACHE: str = \"/content/fmri_cache\"\n",
        "    CKPT_DIR: str = \"/content/checkpoints\"\n",
        "\n",
        "    # training dynamics\n",
        "    BATCH_SIZE: int = 8  # doubled\n",
        "    NUM_WORKERS: int = 4\n",
        "    PIN_MEMORY: bool = True\n",
        "    PERSISTENT_WORKERS: bool = True\n",
        "    USE_AMP: bool = True\n",
        "    GRADIENT_ACCUMULATION_STEPS: int = 4  # halved bc batch doubled\n",
        "\n",
        "    # optimization\n",
        "    LEARNING_RATE: float = 1e-4  # increased\n",
        "    WEIGHT_DECAY: float = 0.1    # doubled\n",
        "    NUM_EPOCHS: int = 30\n",
        "    GRAD_CLIP: float = 0.5       # halved\n",
        "    WARMUP_EPOCHS: int = 3       # reduced\n",
        "    MIN_LR: float = 1e-6\n",
        "\n",
        "    # architecture\n",
        "    VOLUME_SIZE: Tuple[int, int, int] = (64, 64, 30)\n",
        "    PATCH_SIZE: int = 7\n",
        "    NUM_PATCHES: int = (64//7 * 64//7 * 30//7)\n",
        "    TIME_STEPS: int = 32\n",
        "    EMBED_DIM: int = 192         # wider better than deeper for fmri\n",
        "    NUM_HEADS: int = 6           # dim/32 ratio optimal\n",
        "    NUM_LAYERS: int = 4          # retain shallow for spatiotemporal\n",
        "    DROPOUT: float = 0.15        # sweet spot from latest lit\n",
        "\n",
        "    # misc\n",
        "    PATIENCE: int = 15\n",
        "    MIN_DELTA: float = 1e-3\n",
        "    TASK_DIM: int = 256         # halved\n",
        "    KFAC_UPDATE_FREQ: int = 10\n",
        "\n",
        "    # device props\n",
        "    @property\n",
        "    def device(self) -> torch.device:\n",
        "        return device\n",
        "\n",
        "    @property\n",
        "    def fp16(self) -> bool:\n",
        "        return self.USE_AMP\n",
        "\n",
        "    # task info (unchanged)\n",
        "    TASK_INFO: Dict = field(default_factory=lambda: {\n",
        "        'ds000002': {'type': 'prob_class', 'tr': 2.0},\n",
        "        'ds000011': {'type': 'det_class', 'tr': 1.5},\n",
        "        'ds000017': {'type': 'reversal', 'tr': 2.5},\n",
        "        'ds000052': {'type': 'learning', 'tr': 2.0}\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "n9L2DDrr7K5E"
      },
      "outputs": [],
      "source": [
        "@dataclass(frozen=True)\n",
        "class DataConfig:\n",
        "    ROOT: str = \"/content/drive/MyDrive/learnedSpectrum\"\n",
        "    CACHE: str = \"/content/fmri_cache\"\n",
        "    DATASET_PATHS: Dict[str, str] = field(default_factory=lambda: {\n",
        "        'ds000002': 'classification/probabilistic',\n",
        "        'ds000011': 'classification/deterministic',\n",
        "        'ds000017': 'learning/reversal',\n",
        "        'ds000052': 'learning/stages'\n",
        "    })\n",
        "    TASK_INFO: Dict[str, Dict] = field(default_factory=lambda: {\n",
        "        'ds000002': {'type': 'prob_class', 'tr': 2.0},\n",
        "        'ds000011': {'type': 'det_class', 'tr': 1.5},\n",
        "        'ds000017': {'type': 'reversal', 'tr': 2.5},\n",
        "        'ds000052': {'type': 'learning', 'tr': 2.0}\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iibqNhyO7K5E"
      },
      "source": [
        "Print current GPU memory usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "5Q_ArbdZ7K5E"
      },
      "outputs": [],
      "source": [
        "def print_gpu_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU Memory: {torch.cuda.memory_allocated()/1e9:.2f}GB allocated, \"\n",
        "              f\"{torch.cuda.max_memory_allocated()/1e9:.2f}GB peak\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "7Qr1fEq-7K5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcabcd18-3982-4117-d25b-548213e5eab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Memory: 0.17GB allocated, 0.32GB peak\n"
          ]
        }
      ],
      "source": [
        "config = Config()\n",
        "print_gpu_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWDJfejv7K5E"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "1CyKBUDk7K5E"
      },
      "outputs": [],
      "source": [
        "class DatasetManager:\n",
        "    DATASETS = {\n",
        "        'ds000002': {\n",
        "            'url': 'https://s3.amazonaws.com/openneuro/ds000002/ds000002_R2.0.5/compressed/ds000002_R2.0.5_raw.zip',\n",
        "            'tr': 2.0,\n",
        "            'stage_map': lambda f: 0.25 if 'run-2' in str(f) else 0.0  # prob learning\n",
        "        },\n",
        "        'ds000011': {\n",
        "            'url': 'https://s3.amazonaws.com/openneuro/ds000011/ds000011_R2.0.1/compressed/ds000011_R2.0.1_raw.zip',\n",
        "            'tr': 1.5,\n",
        "            'stage_map': lambda f: 0.5 if 'run-2' in str(f) else 0.25  # det learning\n",
        "        },\n",
        "        'ds000017': {\n",
        "            'url': 'https://s3.amazonaws.com/openneuro/ds000017/ds000017_R2.0.1/compressed/ds000017_R2.0.1.zip',\n",
        "            'tr': 2.5,\n",
        "            'stage_map': lambda f: 0.75 if 'run-2' in str(f) else 0.5  # reversal\n",
        "        },\n",
        "        'ds000052': {\n",
        "            'url': 'https://s3.amazonaws.com/openneuro/ds000052/ds000052_R2.0.0/compressed/ds052_R2.0.0_01-14.tgz',\n",
        "            'tr': 2.0,\n",
        "            'stage_map': lambda f: 1.0 if ('reversal' in str(f) and 'run-2' in str(f)) else\n",
        "                                  0.67 if ('reversal' in str(f)) else\n",
        "                                  0.33 if 'run-2' in str(f) else 0.0  # full spectrum\n",
        "        }\n",
        "    }\n",
        "\n",
        "    def __init__(self, config: DataConfig):\n",
        "        self.config = config\n",
        "        self.root = Path(config.ROOT).resolve()\n",
        "        self._mount_drive()\n",
        "\n",
        "    def _mount_drive(self):\n",
        "        if not Path('/content/drive').exists():\n",
        "            drive.mount('/content/drive')\n",
        "        self.root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def _fetch_dataset(self, ds_id: str):\n",
        "        path = self.root/ds_id\n",
        "        if not path.exists():\n",
        "            print(f\"{ds_id} not found.\")\n",
        "            print(f\"manual steps:\")\n",
        "            print(f\"1. wget {self.DATASETS[ds_id]['url']}\")\n",
        "            print(f\"2. extract to {path}\")\n",
        "            raise FileNotFoundError(f\"download {ds_id} first\")\n",
        "\n",
        "    def _exists_and_valid(self, ds_id: str) -> bool:\n",
        "        path = self.root/ds_id\n",
        "        print(f\"checking {ds_id} at: {path}\")\n",
        "        return path.exists() and any(path.glob('**/*bold.nii.gz'))\n",
        "\n",
        "    def fetch_datasets(self):\n",
        "        for ds_id in self.DATASETS:\n",
        "            if not self._exists_and_valid(ds_id):\n",
        "                self._fetch_dataset(ds_id)\n",
        "\n",
        "    def get_all_files(self) -> Dict[str, List[Path]]:\n",
        "        return {\n",
        "            ds_id: list(self.root.glob(f\"{ds_id}/**/*bold.nii.gz\"))\n",
        "            for ds_id in self.DATASETS\n",
        "            if self._exists_and_valid(ds_id)\n",
        "        }\n",
        "\n",
        "    def get_learning_stages(self) -> Dict[str, float]:\n",
        "        stages = {}\n",
        "        for ds_id, files in self.get_all_files().items():\n",
        "            stage_map = self.DATASETS[ds_id]['stage_map']\n",
        "            for f in files:\n",
        "                stages[f.parts[-3]] = stage_map(f)\n",
        "        return stages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "9gbqHFSr7K5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e82ca713-1932-4dc2-e326-a75e7f598233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checking ds000002 at: /content/drive/MyDrive/learnedSpectrum/ds000002\n",
            "checking ds000011 at: /content/drive/MyDrive/learnedSpectrum/ds000011\n",
            "checking ds000017 at: /content/drive/MyDrive/learnedSpectrum/ds000017\n",
            "checking ds000052 at: /content/drive/MyDrive/learnedSpectrum/ds000052\n",
            "checking ds000002 at: /content/drive/MyDrive/learnedSpectrum/ds000002\n",
            "checking ds000011 at: /content/drive/MyDrive/learnedSpectrum/ds000011\n",
            "checking ds000017 at: /content/drive/MyDrive/learnedSpectrum/ds000017\n",
            "checking ds000052 at: /content/drive/MyDrive/learnedSpectrum/ds000052\n",
            "checking ds000002 at: /content/drive/MyDrive/learnedSpectrum/ds000002\n",
            "checking ds000011 at: /content/drive/MyDrive/learnedSpectrum/ds000011\n",
            "checking ds000017 at: /content/drive/MyDrive/learnedSpectrum/ds000017\n",
            "checking ds000052 at: /content/drive/MyDrive/learnedSpectrum/ds000052\n"
          ]
        }
      ],
      "source": [
        "manager = DatasetManager(config)\n",
        "manager.fetch_datasets()\n",
        "files = manager.get_all_files()\n",
        "stages = manager.get_learning_stages()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xgqJygu7K5E"
      },
      "source": [
        "## Create datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "extract region activations using aal atlas\n",
        "\n",
        "data: [T,H,W,D] fmri timeseries"
      ],
      "metadata": {
        "id": "MdzZe55cTf_Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "l6LYtsSo7K5E"
      },
      "outputs": [],
      "source": [
        "def extract_aal_regions(data: torch.Tensor) -> torch.Tensor:\n",
        "    aal = load_aal_atlas()\n",
        "\n",
        "    regions = torch.zeros(116)\n",
        "    for i in range(116):\n",
        "        mask = (aal == i+1)\n",
        "        if mask.any():\n",
        "            regions[i] = data[:, mask].mean()\n",
        "\n",
        "    regions = (regions - regions.mean()) / (regions.std() + 1e-6)\n",
        "    return regions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "extract temporal dynamics using wavelet decomp\n",
        "\n",
        "data: [T,H,W,D] fmri timeseries\n",
        "\n",
        "returns: [n_components] frequency features"
      ],
      "metadata": {
        "id": "F1Q95NAYTm6B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "01L4EyLS7K5F"
      },
      "outputs": [],
      "source": [
        "def extract_temporal_patterns(data: torch.Tensor, n_components: int = 32) -> torch.Tensor:\n",
        "\n",
        "    signal = data.reshape(data.shape[0], -1).mean(1)\n",
        "\n",
        "    coeffs = wavedec(signal, 'db4', level=int(np.log2(len(signal))))\n",
        "\n",
        "    features = torch.cat([torch.from_numpy(c) for c in coeffs])\n",
        "    return features[:n_components]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "0XsAapDf7K5F"
      },
      "outputs": [],
      "source": [
        "class BIDSManager:\n",
        "    def __init__(self, dataset_id='ds000052', path='data/'):\n",
        "        self.dataset_id = dataset_id\n",
        "        self.root = Path(path)\n",
        "        self.root.mkdir(exist_ok=True)\n",
        "        self._fetch_dataset()\n",
        "\n",
        "    def _fetch_dataset(self):\n",
        "        if not (self.root/self.dataset_id).exists():\n",
        "            url = \"https://s3.amazonaws.com/openneuro/ds000052/ds000052_R2.0.0/compressed/ds052_R2.0.0_01-14.tgz\"\n",
        "            target = self.root/'data.tgz'\n",
        "\n",
        "            import requests\n",
        "            r = requests.get(url, stream=True)\n",
        "            r.raise_for_status()\n",
        "\n",
        "            with open(target, 'wb') as f:\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "\n",
        "            import tarfile\n",
        "            with tarfile.open(target) as tf:\n",
        "                tf.extractall(self.root)\n",
        "            target.unlink()\n",
        "\n",
        "    def get_task_files(self, task='weatherprediction'):\n",
        "        return sorted(self.root.glob(f\"**/*task-{task}*_bold.nii.gz\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "tE_MR8lA7K5F"
      },
      "outputs": [],
      "source": [
        "class FMRIDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        root='data/',\n",
        "        tr=2.0,\n",
        "        n_timepoints=30,\n",
        "        n_regions=116,\n",
        "        validate=True,\n",
        "        cache_size=50\n",
        "    ):\n",
        "        self.manager = BIDSManager(path=root)\n",
        "        self.tr = tr\n",
        "        self.n_timepoints = n_timepoints\n",
        "        self.n_regions = n_regions\n",
        "        self.files = self._get_valid_files() if validate else self.manager.get_task_files()\n",
        "        self.labels = self._extract_learning_stages()\n",
        "        self.cache = LRUCache(size=cache_size)\n",
        "\n",
        "        self.atlas = self._load_aal_atlas()\n",
        "\n",
        "        self.time_indices = np.array([\n",
        "            int(re.search(r'run-(\\d+)', str(f)).group(1))\n",
        "            for f in self.files\n",
        "        ])\n",
        "\n",
        "    def _get_valid_files(self):\n",
        "        valid = []\n",
        "        for f in tqdm(self.manager.get_task_files(), desc='validating niftis'):\n",
        "            if self._validate_nifti(f):\n",
        "                valid.append(f)\n",
        "\n",
        "        if not valid:\n",
        "            raise ValueError(\"no valid niftis. check bids structure.\")\n",
        "\n",
        "        return valid\n",
        "\n",
        "    def _validate_nifti(self, f):\n",
        "        try:\n",
        "            img = nib.load(str(f))\n",
        "            data = img.get_fdata(dtype=np.float32)\n",
        "            return (data.ndim == 4 and\n",
        "                   not np.any(np.isnan(data)) and\n",
        "                   not np.any(np.isinf(data)) and\n",
        "                   data.shape[-1] >= self.n_timepoints)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"invalid nifti {f}: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def _load_aal_atlas(self):\n",
        "        from nilearn.datasets import fetch_atlas_aal\n",
        "        atlas = fetch_atlas_aal()\n",
        "        return nib.load(atlas['maps']).get_fdata()\n",
        "\n",
        "    def _extract_aal_regions(self, data):\n",
        "        regions = torch.zeros(self.n_regions)\n",
        "        for i in range(self.n_regions):\n",
        "            mask = (self.atlas == i+1)\n",
        "            if mask.any():\n",
        "                regions[i] = data[:, mask].mean()\n",
        "        return (regions - regions.mean()) / (regions.std() + 1e-6)\n",
        "\n",
        "    def _extract_temporal_patterns(self, data):\n",
        "        signal = data.reshape(data.shape[0], -1).mean(1)\n",
        "        level = min(int(np.log2(len(signal))-2), 3)\n",
        "        coeffs = wavedec(signal, 'db4', level=level)\n",
        "        features = torch.cat([torch.from_numpy(c) for c in coeffs])\n",
        "        if len(features) < self.n_timepoints:\n",
        "            features = F.pad(features, (0, self.n_timepoints - len(features)))\n",
        "        return features[:self.n_timepoints]\n",
        "\n",
        "    def _extract_learning_stages(self):\n",
        "        stages = {}\n",
        "        for f in self.files:\n",
        "            if 'reversal' in str(f):\n",
        "                stages[f.parts[-3]] = 1.0 if 'run-2' in str(f) else 0.67\n",
        "            else:\n",
        "                stages[f.parts[-3]] = 0.33 if 'run-2' in str(f) else 0.0\n",
        "        return stages\n",
        "\n",
        "    def _load_sample(self, idx):\n",
        "        fpath = self.files[idx]\n",
        "        if fpath in self.cache:\n",
        "            return self.cache[fpath]\n",
        "\n",
        "        img = nib.load(str(fpath))\n",
        "        data = img.get_fdata(dtype=np.float32)\n",
        "\n",
        "        data = (data - data.mean()) / (data.std() + 1e-6)\n",
        "        data = data[...,:self.n_timepoints]\n",
        "\n",
        "        data = torch.from_numpy(data).float()\n",
        "        data = data.permute(3,0,1,2)\n",
        "        regions = self._extract_aal_regions(data)\n",
        "        temporal = self._extract_temporal_patterns(data)\n",
        "\n",
        "        label = self.labels[fpath.parts[-3]]\n",
        "\n",
        "        sample = (data, regions, temporal, label)\n",
        "        self.cache[fpath] = sample\n",
        "        return sample\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data, regions, temporal, label = self._load_sample(idx)\n",
        "        task_id = self.task_ids[idx] if hasattr(self, 'task_ids') else 0\n",
        "\n",
        "        return data, task_id, {\n",
        "            'learning_stage': float(label),\n",
        "            'region_activation': regions,\n",
        "            'temporal_pattern': temporal\n",
        "        }\n",
        "\n",
        "        return data, task_id, targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct6ABWbQ7K5F"
      },
      "source": [
        "## Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "CszEs5MZ7K5F"
      },
      "outputs": [],
      "source": [
        "def create_dataloaders(dataset, config, split=0.8):\n",
        "    indices = np.arange(len(dataset))\n",
        "    split_idx = int(len(indices) * split)\n",
        "\n",
        "    train_indices = indices[:split_idx]\n",
        "    val_indices = indices[split_idx:]\n",
        "\n",
        "    train_set = torch.utils.data.Subset(dataset, train_indices)\n",
        "    val_set = torch.utils.data.Subset(dataset, val_indices)\n",
        "\n",
        "    loader_kwargs = {\n",
        "        'batch_size': max(1, config.BATCH_SIZE // 2),\n",
        "        'num_workers': config.NUM_WORKERS,\n",
        "        'pin_memory': True,\n",
        "        'collate_fn': collate_fn\n",
        "    }\n",
        "    train_loader = DataLoader(train_set, shuffle=True, **loader_kwargs)\n",
        "    val_loader = DataLoader(val_set, shuffle=False, **loader_kwargs)\n",
        "\n",
        "\n",
        "    return (\n",
        "        DataLoader(train_set, shuffle=True, **loader_kwargs),\n",
        "        DataLoader(val_set, shuffle=False, **loader_kwargs)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "2tFUnXyR7K5F"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    data, task_ids, targets = zip(*batch)\n",
        "\n",
        "    x = torch.stack(data).squeeze(1)\n",
        "    x = x.permute(0,1,3,4,2)\n",
        "    task_ids = torch.tensor(task_ids)\n",
        "\n",
        "    batch_targets = {}\n",
        "    for k in targets[0].keys():\n",
        "        if isinstance(targets[0][k], (float, int)):\n",
        "            try:\n",
        "                batch_targets[k] = torch.tensor([t[k] for t in targets])\n",
        "            except ValueError as e:\n",
        "                print(f\"collate fail on {k}: {[t[k] for t in targets]}\")\n",
        "                raise e\n",
        "        else:\n",
        "            batch_targets[k] = torch.stack([t[k] for t in targets])\n",
        "\n",
        "    return x, task_ids, batch_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "rWd2Recg7K5F"
      },
      "outputs": [],
      "source": [
        "def collate_variable_length(batch):\n",
        "    data, task_ids, targets = zip(*batch)\n",
        "\n",
        "    x = torch.stack(data).squeeze(1)\n",
        "    x = x.permute(0, 1, 3, 4, 2)\n",
        "    task_ids = torch.tensor(task_ids)\n",
        "\n",
        "    batch_targets = {}\n",
        "    for k in targets[0].keys():\n",
        "        if isinstance(targets[0][k], (float, int)):\n",
        "            batch_targets[k] = torch.tensor([t[k] for t in targets])\n",
        "        else:\n",
        "            batch_targets[k] = torch.stack([t[k] for t in targets])\n",
        "\n",
        "    return x, task_ids, batch_targets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ensure proper pinned memory cleanup"
      ],
      "metadata": {
        "id": "x12-1XimUQZj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "t8k2TOvC7K5F"
      },
      "outputs": [],
      "source": [
        "class PinnedMemoryContext:\n",
        "    def __enter__(self):\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    def __exit__(self, *args):\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "def get_loader_stats(loader: DataLoader) -> Dict[str, int]:\n",
        "    \"\"\"debug utility\"\"\"\n",
        "    return {\n",
        "        'batches': len(loader),\n",
        "        'samples': len(loader.dataset),\n",
        "        'device_batch': loader.batch_size,\n",
        "        'effective_batch': loader.batch_size * config.GRADIENT_ACCUMULATION_STEPS\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "synthetic task labels, 4 stages w/ proper progression"
      ],
      "metadata": {
        "id": "90Rt7HYjUSPT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "sfZu1Xba7K5F"
      },
      "outputs": [],
      "source": [
        "def get_mock_labels():\n",
        "    return {\n",
        "        'sub-01': 0.0,    # naive performance\n",
        "        'sub-02': 0.25,   # early learning\n",
        "        'sub-03': 0.50,   # intermediate mastery\n",
        "        'sub-04': 0.75,   # advanced competence\n",
        "        'sub-05': 1.0     # expert performance\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTC-6WWX7K5F"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "B4Qku1Dv7K5F"
      },
      "outputs": [],
      "source": [
        "def preprocess_volume(vol: np.ndarray, config: Config) -> torch.Tensor:\n",
        "    if vol.ndim not in (4,5):\n",
        "        raise ValueError(f\"expect 4d/5d vol, got {vol.ndim}d\")\n",
        "\n",
        "    if vol.ndim == 4:\n",
        "        vol = vol[None]\n",
        "\n",
        "    b,t,h,w,d = vol.shape\n",
        "    target_h, target_w, target_d = config.VOLUME_SIZE\n",
        "\n",
        "    vol = zoom(vol, (\n",
        "        1,\n",
        "        1,\n",
        "        target_h/h,\n",
        "        target_w/w,\n",
        "        target_d/d\n",
        "    ), order=1)\n",
        "\n",
        "    vol = (vol - vol.mean((1,2,3,4), keepdims=True)) / (vol.std((1,2,3,4), keepdims=True) + 1e-8)\n",
        "\n",
        "    return torch.from_numpy(vol).float()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "enforce temporal consistency"
      ],
      "metadata": {
        "id": "ra8Dtv1LUi77"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "1Nz9eHbO7K5G"
      },
      "outputs": [],
      "source": [
        "def normalize_temporal_resolution(data: np.ndarray, orig_tr: float = 2.0, target_tr: float = 2.0) -> np.ndarray:\n",
        "    if orig_tr == target_tr:\n",
        "        return data\n",
        "\n",
        "    old_times = np.arange(0, data.shape[-1]) * orig_tr\n",
        "    new_times = np.arange(0, old_times[-1], target_tr)\n",
        "\n",
        "    orig_shape = data.shape\n",
        "    data_2d = data.reshape(-1, orig_shape[-1])\n",
        "\n",
        "    interp_data = np.array([\n",
        "        interp1d(old_times, ts, kind='cubic', bounds_error=False, fill_value='extrapolate')(new_times)\n",
        "        for ts in data_2d\n",
        "    ])\n",
        "\n",
        "    return interp_data.reshape(*orig_shape[:-1], len(new_times))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "84S5aT-B7K5G"
      },
      "outputs": [],
      "source": [
        "class FMRIAugmentor:\n",
        "    def __init__(self, p=0.5):\n",
        "        self.p = p\n",
        "        self.augs = [\n",
        "            self._temporal_shift,\n",
        "            self._gaussian_noise,\n",
        "            self._dropout_voxels,\n",
        "            self._mixup,\n",
        "            self._intensity_scale\n",
        "        ]\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if random.random() < self.p:\n",
        "            aug = random.choice(self.augs)\n",
        "            x = aug(x)\n",
        "        return x\n",
        "\n",
        "    def _temporal_shift(self, x, max_shift=3):\n",
        "        shift = random.randint(-max_shift, max_shift)\n",
        "        return torch.roll(x, shifts=shift, dims=1)\n",
        "\n",
        "    def _gaussian_noise(self, x, std=0.01):\n",
        "        return x + torch.randn_like(x) * std\n",
        "\n",
        "    def _dropout_voxels(self, x, p=0.1):\n",
        "        mask = torch.rand_like(x) > p\n",
        "        return x * mask\n",
        "\n",
        "    def _mixup(self, x, alpha=0.2):\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "        idx = torch.randperm(x.size(0))\n",
        "        return lam * x + (1-lam) * x[idx]\n",
        "\n",
        "    def _intensity_scale(self, x, range=(0.9, 1.1)):\n",
        "        scale = random.uniform(*range)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dwFcu7Z7K5G"
      },
      "source": [
        "## 3D Vision Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "DbgVrjwt7K5G"
      },
      "outputs": [],
      "source": [
        "class HierarchicalAttention(nn.Module):\n",
        "    def __init__(self, dim, heads=8, dim_head=64):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.local_attn = nn.MultiheadAttention(dim, heads, batch_first=True)\n",
        "        self.global_attn = nn.MultiheadAttention(dim, heads, batch_first=True)\n",
        "        self.merge = nn.Linear(dim * 2, dim)\n",
        "\n",
        "        self.task_gate = nn.Sequential(\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, task_embed=None):\n",
        "        b, n, _ = x.shape\n",
        "        local_out = self.local_attn(x, x, x)[0]\n",
        "\n",
        "        if task_embed is not None:\n",
        "            task_gate = self.task_gate(task_embed).unsqueeze(1)\n",
        "            x = x * task_gate\n",
        "\n",
        "        global_out = self.global_attn(x, x, x)[0]\n",
        "        return self.merge(torch.cat([local_out, global_out], dim=-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "8g69tqrG7K5G"
      },
      "outputs": [],
      "source": [
        "class TaskConditionedMLP(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim=None):\n",
        "        super().__init__()\n",
        "        hidden_dim = hidden_dim or dim * 4\n",
        "\n",
        "        self.task_gate = nn.Sequential(\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, task_embed):\n",
        "        gate = self.task_gate(task_embed).unsqueeze(1)\n",
        "        return self.net(x * gate)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gating between local/global temporal patterns"
      ],
      "metadata": {
        "id": "3hjNQns4Usur"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "H3VskDxU7K5G"
      },
      "outputs": [],
      "source": [
        "class AdaptiveTokenMixer(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3)\n",
        "        self.local_proj = nn.Linear(dim, dim)\n",
        "        self.global_proj = nn.Linear(dim, dim)\n",
        "        self.gate = nn.Linear(dim, 1)\n",
        "\n",
        "        self.temp = nn.Parameter(torch.ones(1, num_heads, 1, 1))\n",
        "\n",
        "        self.rel_pos = nn.Parameter(torch.randn(2 * dim - 1, head_dim))\n",
        "        pos_index = torch.arange(dim)\n",
        "        rel_pos_index = pos_index[None, :] - pos_index[:, None]\n",
        "        rel_pos_index += dim - 1\n",
        "        self.register_buffer('rel_pos_index', rel_pos_index)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        B, N, C = x.shape\n",
        "\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads)\n",
        "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv.unbind(0)\n",
        "\n",
        "        rel_pos_bias = self.rel_pos[self.rel_pos_index].permute(2, 0, 1)\n",
        "\n",
        "        attn = ((q @ k.transpose(-2, -1)) * self.scale + rel_pos_bias) * self.temp\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, float('-inf'))\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        local_out = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        global_out = self.global_proj(x)\n",
        "\n",
        "        gate = self.gate(x).sigmoid()\n",
        "        x = gate * local_out + (1 - gate) * global_out\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "xESgVkyH7K5G"
      },
      "outputs": [],
      "source": [
        "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
        "    omega = np.arange(embed_dim // 2, dtype=np.float32)\n",
        "    omega /= embed_dim / 2.\n",
        "    omega = 1. / 10000**omega\n",
        "    pos = pos.reshape(-1)\n",
        "    out = np.einsum('m,d->md', pos, omega)\n",
        "    emb_sin = np.sin(out)\n",
        "    emb_cos = np.cos(out)\n",
        "    emb = np.concatenate([emb_sin, emb_cos], axis=1)\n",
        "    return emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "Yujfl64y7K5G"
      },
      "outputs": [],
      "source": [
        "def get_3d_sincos_pos_embed(embed_dim, dims, cls_token=True):\n",
        "    h, w, d = dims\n",
        "    total_pos = h * w * d\n",
        "    pos = get_1d_sincos_pos_embed_from_grid(embed_dim, np.arange(total_pos))\n",
        "\n",
        "    if cls_token:\n",
        "        return np.concatenate([np.zeros((1, embed_dim)), pos])\n",
        "    return pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "Llj0HGZ07K5G"
      },
      "outputs": [],
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.eps = 1e-6\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        freqs = torch.bincount(target.long(), minlength=2).float()\n",
        "        freqs = freqs / freqs.sum()\n",
        "        gamma = self.gamma * (1 - freqs[target.long()])\n",
        "\n",
        "        ce = F.binary_cross_entropy_with_logits(pred, target, reduction='none')\n",
        "        p = torch.sigmoid(pred)\n",
        "        p_t = p * target + (1 - p) * (1 - target)\n",
        "        alpha_t = self.alpha * target + (1 - self.alpha) * (1 - target)\n",
        "\n",
        "        loss = alpha_t * ((1 - p_t) ** gamma) * ce\n",
        "        return loss.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "SKfdaYLn7K5G"
      },
      "outputs": [],
      "source": [
        "class RegressionFocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.eps = 1e-6\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = torch.clamp(pred, self.eps, 1-self.eps)\n",
        "\n",
        "        base_loss = F.mse_loss(pred, target, reduction='none')\n",
        "        alpha_t = self.alpha + (1-self.alpha) * target\n",
        "\n",
        "        pt = torch.exp(-base_loss)\n",
        "        focal_weight = (1 - pt) ** self.gamma * alpha_t\n",
        "\n",
        "        return (focal_weight * base_loss).mean()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightedMultiTaskLoss(nn.Module):\n",
        "    def __init__(self, device):\n",
        "        super().__init__()\n",
        "        self.stage_loss = OrdinalFocalLoss()\n",
        "        self.contrast_loss = ContrastiveLoss(temperature=0.1)\n",
        "\n",
        "    def forward(self, outputs, targets, epoch=None):\n",
        "        stage_out = outputs['learning_stage'].squeeze()\n",
        "        stage_target = targets['learning_stage']\n",
        "\n",
        "        if stage_out.ndim == 1:\n",
        "            stage_out = stage_out.unsqueeze(-1)\n",
        "        if stage_target.ndim == 1:\n",
        "            stage_target = stage_target.unsqueeze(-1)\n",
        "\n",
        "        # scale losses\n",
        "        stage_loss = self.stage_loss(stage_out, stage_target)\n",
        "        contrast_loss = 0.0\n",
        "\n",
        "        if epoch and epoch > 5:\n",
        "            x1, x2 = pretrain_transform(outputs['features'])\n",
        "            contrast_loss = 0.01 * self.contrast_loss(x1, x2)\n",
        "\n",
        "        loss = stage_loss + contrast_loss\n",
        "        return loss, {\n",
        "            'stage_loss': stage_loss.item(),\n",
        "            'contrast_loss': contrast_loss if isinstance(contrast_loss, float) else contrast_loss.item()\n",
        "        }"
      ],
      "metadata": {
        "id": "ubt_l8FI5RhD"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EntropyRegularizer(nn.Module):\n",
        "    def __init__(self, alpha=0.1, temperature=1.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, stage_preds):\n",
        "        # normalize predictions\n",
        "        probs = stage_preds / self.temperature\n",
        "\n",
        "        # compute entropy\n",
        "        entropy = -(probs * torch.log(probs + 1e-8)).sum(dim=1).mean()\n",
        "\n",
        "        # target entropy (uniform dist)\n",
        "        target_entropy = -torch.log(torch.tensor(1.0 / probs.size(1)))\n",
        "\n",
        "        return self.alpha * (target_entropy - entropy).abs()"
      ],
      "metadata": {
        "id": "wGZukFpu_JWp"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StagePredictor(nn.Module):\n",
        "    def __init__(self, dim, num_stages=4):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim*2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(dim*2, num_stages)\n",
        "        )\n",
        "\n",
        "        # initialization for better gradient flow\n",
        "        for m in self.net:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.orthogonal_(m.weight, gain=1/np.sqrt(2))\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.net(x)\n",
        "        return F.softmax(logits, dim=1)"
      ],
      "metadata": {
        "id": "cG1XlK25_KqM"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "ECcc59cy7K5G"
      },
      "outputs": [],
      "source": [
        "class TemporalAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.embed_dim = config.EMBED_DIM\n",
        "        self.num_heads = 8\n",
        "        self.head_dim = self.embed_dim // self.num_heads\n",
        "\n",
        "        self.qkv = nn.Linear(self.embed_dim, 3 * self.embed_dim)\n",
        "        self.proj = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "\n",
        "        # relative positional bias\n",
        "        self.rel_pos_bias = nn.Parameter(\n",
        "            torch.zeros(2 * config.TIME_STEPS - 1, self.num_heads)\n",
        "        )\n",
        "        pos_index = torch.arange(config.TIME_STEPS)\n",
        "        rel_pos_index = pos_index[None, :] - pos_index[:, None]\n",
        "        rel_pos_index += config.TIME_STEPS - 1\n",
        "        self.register_buffer('rel_pos_index', rel_pos_index)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "\n",
        "        # qkv projection\n",
        "        qkv = self.qkv(x).reshape(B, T, 3, self.num_heads, self.head_dim)\n",
        "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv.unbind(0)\n",
        "\n",
        "        # attention w/relative pos bias\n",
        "        attn = (q @ k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "        attn = attn + self.rel_pos_bias[self.rel_pos_index]\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        # aggregate and project\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, T, C)\n",
        "        x = self.proj(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "fw_jJjTR7K5G"
      },
      "outputs": [],
      "source": [
        "class WeightedMSE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.base = nn.MSELoss(reduction='none')\n",
        "\n",
        "    def forward(self, pred, true):\n",
        "        conf = 1 - torch.abs(true - 0.5) * 2\n",
        "        loss = self.base(pred, true)\n",
        "        return (loss * conf).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "mw7wybDD7K5G"
      },
      "outputs": [],
      "source": [
        "def shape_hook(name):\n",
        "    def hook(module, input, output):\n",
        "        if not hasattr(hook, 'count'):\n",
        "            hook.count = 0\n",
        "        hook.count += 1\n",
        "        if hook.count <= 2:\n",
        "            print(f\"{name} in:\", [x.shape if isinstance(x, torch.Tensor) else None for x in input])\n",
        "            print(f\"{name} out:\", output[0].shape if isinstance(output, tuple) else output.shape)\n",
        "    return hook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "ZEloFOXj7K5G"
      },
      "outputs": [],
      "source": [
        "class StageHead(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.in_norm = nn.LayerNorm(dim)\n",
        "        self.proj1 = nn.Linear(dim, dim)\n",
        "        self.mid_norm = nn.LayerNorm(dim)\n",
        "        self.proj2 = nn.Linear(dim, dim//2)\n",
        "        self.out_norm = nn.LayerNorm(dim//2)\n",
        "        self.out = nn.Linear(dim//2, 1)\n",
        "        self.act = nn.GELU()\n",
        "\n",
        "        nn.init.orthogonal_(self.proj1.weight, gain=1/np.sqrt(2))\n",
        "        nn.init.orthogonal_(self.proj2.weight, gain=1/np.sqrt(2))\n",
        "        nn.init.orthogonal_(self.out.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.in_norm(x)\n",
        "        h = self.act(self.proj1(h))\n",
        "        h = self.mid_norm(h + x)\n",
        "        h = self.act(self.proj2(h))\n",
        "        h = self.out_norm(h)\n",
        "\n",
        "        return torch.sigmoid(self.out(h))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "OaxGIyRE7K5H"
      },
      "outputs": [],
      "source": [
        "class TaskGate(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(dim, dim//2),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim//2, dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.scale = nn.Parameter(torch.ones(1) * 0.1)\n",
        "\n",
        "    def forward(self, x, task):\n",
        "        g = self.gate(self.norm(task))\n",
        "        return x * (g * self.scale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "IX9xhHQa7K5H"
      },
      "outputs": [],
      "source": [
        "class WaveletDecomp(nn.Module):\n",
        "    def __init__(self, n_levels=4, wavelet='db4'):\n",
        "        super().__init__()\n",
        "        self.n_levels = n_levels\n",
        "        self.wavelet = wavelet\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_np = x.detach().cpu().numpy()\n",
        "        coeffs = []\n",
        "\n",
        "        for i in range(len(x_np)):\n",
        "            c = pywt.wavedec(\n",
        "                x_np[i], self.wavelet,\n",
        "                level=self.n_levels\n",
        "            )\n",
        "            coeffs.append(np.concatenate(c))\n",
        "\n",
        "        return torch.from_numpy(\n",
        "            np.stack(coeffs)\n",
        "        ).float().to(x.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "AtYTJn9-7K5H"
      },
      "outputs": [],
      "source": [
        "class ScaleNorm(nn.Module):\n",
        "    def __init__(self, dim, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.scale = nn.Parameter(torch.ones(1) * dim ** 0.5)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        norm = self.scale / torch.norm(x, dim=-1, keepdim=True).clamp(min=self.eps)\n",
        "        return x * norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "PTB5Wf8D7K5H"
      },
      "outputs": [],
      "source": [
        "class WaveletTemporal(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.embed_dim = config.EMBED_DIM\n",
        "\n",
        "        # spatial -> temporal flow\n",
        "        self.spatial_proj = nn.Conv3d(1, config.EMBED_DIM, 1).to(config.device)\n",
        "        self.temporal_proj = nn.Conv3d(\n",
        "            config.EMBED_DIM,\n",
        "            config.EMBED_DIM,\n",
        "            (3,1,1),\n",
        "            padding=(1,0,0)\n",
        "        ).to(config.device)\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool3d((15, 32, 32)).to(config.device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # reshape for conv\n",
        "        b, t, h, d, w = x.shape\n",
        "        x = x.reshape(b, 1, t, h, w*d)\n",
        "\n",
        "        # projections\n",
        "        x = self.spatial_proj(x)\n",
        "        x = self.temporal_proj(x)\n",
        "\n",
        "        # force dims\n",
        "        x = self.pool(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def debug_shapes(x):\n",
        "    # input\n",
        "    b,t,h,d,w = x.shape\n",
        "    print(f\"input: {x.shape}\")\n",
        "\n",
        "    # reshape attempt 1\n",
        "    x1 = x.reshape(b, 1, t, h, d*w)\n",
        "    print(f\"reshape1: {x1.shape}\")\n",
        "\n",
        "    # reshape attempt 2\n",
        "    x2 = x.reshape(b, 1, t, h, w*d)\n",
        "    print(f\"reshape2: {x2.shape}\")\n",
        "\n",
        "    # reshape + permute\n",
        "    x3 = x.permute(0,1,2,4,3).reshape(b, 1, t, h, w*d)\n",
        "    print(f\"reshape3: {x3.shape}\")\n",
        "\n",
        "    return x3  # return best version"
      ],
      "metadata": {
        "id": "b9an-c6KEv3Z"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_3d_pos_embedding(num_patches, embed_dim, cls_token=True):\n",
        "    # basic sincos but w/ proper dims\n",
        "    pos = torch.arange(num_patches).unsqueeze(1)\n",
        "    omega = torch.exp(\n",
        "        torch.arange(embed_dim//2, dtype=torch.float32) *\n",
        "        (-math.log(10000.0) / (embed_dim//2))\n",
        "    )\n",
        "    pos_emb = pos * omega\n",
        "    pos_emb = torch.cat([torch.sin(pos_emb), torch.cos(pos_emb)], dim=-1)\n",
        "\n",
        "    return pos_emb"
      ],
      "metadata": {
        "id": "eE9UsCZLHVJ2"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "XdQL6COD7K5H"
      },
      "outputs": [],
      "source": [
        "class SequentialBrainViT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        # aggressive downsampling\n",
        "        self.spatial_proj = nn.Sequential(\n",
        "            nn.Conv3d(30, 32, 3, stride=2, padding=1),  # halve\n",
        "            nn.LayerNorm([32, 32, 11, 32]),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.Conv3d(32, 64, 3, stride=2, padding=1),  # quarter\n",
        "            nn.LayerNorm([64, 16, 6, 16]),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.AdaptiveAvgPool3d((8, 4, 8))  # force smaller dims\n",
        "        )\n",
        "\n",
        "        # ~256 tokens vs 11k before\n",
        "        h, w, d = 8, 4, 8\n",
        "        self.embed_dim = 64\n",
        "        self.num_tokens = h * w * d\n",
        "\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, self.num_tokens, self.embed_dim))\n",
        "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
        "\n",
        "        # fewer layers + heads\n",
        "        self.encoder = nn.ModuleList([\n",
        "            TransformerBlock(self.embed_dim, num_heads=4, mlp_ratio=2)\n",
        "            for _ in range(3)\n",
        "        ])\n",
        "\n",
        "        self.stage_head = nn.Sequential(\n",
        "            nn.LayerNorm(self.embed_dim),\n",
        "            nn.Linear(self.embed_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.trunc_normal_(m.weight, std=0.02)\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.ones_(m.weight)\n",
        "            nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x, task_ids=None):\n",
        "        x = self.spatial_proj(x)\n",
        "        x = x.flatten(2).transpose(1, 2)\n",
        "        x = x + self.pos_embed\n",
        "\n",
        "        for block in self.encoder:\n",
        "            x = block(x)\n",
        "\n",
        "        x = x.mean(1)\n",
        "        return {\n",
        "            'learning_stage': self.stage_head(x),\n",
        "            'features': x\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "fAz84W228AVp"
      },
      "outputs": [],
      "source": [
        "def verify_model_devices(model):\n",
        "    devices = {}\n",
        "    for name, param in model.named_parameters():\n",
        "        devices[name] = param.device\n",
        "    return devices"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pretrain_transform(x, sigma=0.1):\n",
        "    \"\"\"generate two augmented views\"\"\"\n",
        "    x1 = x + torch.randn_like(x) * sigma\n",
        "    x2 = torch.roll(\n",
        "        x + torch.randn_like(x) * sigma,\n",
        "        shifts=random.randint(-3, 3),\n",
        "        dims=1\n",
        "    )\n",
        "    return x1, x2"
      ],
      "metadata": {
        "id": "uaAcndzLbRZQ"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mixup(x, y, alpha=0.2):\n",
        "    \"\"\"mixup augmentation\"\"\"\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(x.device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index]\n",
        "    mixed_y = lam * y + (1 - lam) * y[index]\n",
        "\n",
        "    return mixed_x, mixed_y"
      ],
      "metadata": {
        "id": "AosZ--LEbSpa"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "wufgQcRH7K5H"
      },
      "outputs": [],
      "source": [
        "class StageHead(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(dim * 2, dim // 2),\n",
        "            nn.LayerNorm(dim // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim // 2, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        for m in self.net:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight, gain=0.02)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "lVvq7W4o7K5H"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, mlp_ratio=4, drop_path=0.):\n",
        "        super().__init__()\n",
        "\n",
        "        # attention\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.attn = nn.MultiheadAttention(\n",
        "            dim, num_heads, batch_first=True\n",
        "        )\n",
        "\n",
        "        # ffn\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, dim * mlp_ratio),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(dim * mlp_ratio, dim)\n",
        "        )\n",
        "\n",
        "        # stochastic depth\n",
        "        self.drop_path = DropPath(drop_path)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # residual attention\n",
        "        x = x + self.drop_path(\n",
        "            self.attn(*[self.norm1(x)]*3)[0]\n",
        "        )\n",
        "\n",
        "        # residual ffn\n",
        "        x = x + self.drop_path(\n",
        "            self.mlp(self.norm2(x))\n",
        "        )\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSkgZj7d7K5H"
      },
      "source": [
        "## Train Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "utQ8sZjn7K5H"
      },
      "outputs": [],
      "source": [
        "class SAM(torch.optim.Optimizer):\n",
        "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
        "        assert isinstance(params, (list, tuple)) and len(params) > 0, \"params must be non-empty list\"\n",
        "        defaults = dict(rho=rho, adaptive=adaptive)\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
        "        self.param_groups = self.base_optimizer.param_groups\n",
        "        self.defaults.update(self.base_optimizer.defaults)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def first_step(self, zero_grad=False):\n",
        "        grad_norm = self._grad_norm()\n",
        "        for group in self.param_groups:\n",
        "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None: continue\n",
        "                self.state[p][\"old_p\"] = p.data.clone()\n",
        "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n",
        "                p.add_(e_w)\n",
        "        if zero_grad: self.zero_grad()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def second_step(self, zero_grad=False):\n",
        "        for group in self.param_groups:\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None: continue\n",
        "                p.data = self.state[p][\"old_p\"]\n",
        "        self.base_optimizer.step()\n",
        "        if zero_grad: self.zero_grad()\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        assert closure is not None, \"SAM requires closure\"\n",
        "        with torch.enable_grad():\n",
        "            loss = closure()\n",
        "        self.first_step(zero_grad=True)\n",
        "        with torch.enable_grad():\n",
        "            closure()\n",
        "        self.second_step()\n",
        "        return loss\n",
        "\n",
        "    def _grad_norm(self):\n",
        "        grads = [p.grad for group in self.param_groups for p in group[\"params\"] if p.grad is not None]\n",
        "        if not grads:\n",
        "            return torch.tensor(0.0, device=self.param_groups[0][\"params\"][0].device)\n",
        "        return torch.norm(torch.stack([g.norm(p=2) for g in grads]), p=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "Z1s0VxfD7K5H"
      },
      "outputs": [],
      "source": [
        "class KFAC(torch.optim.Optimizer):\n",
        "    def __init__(self, model, lr=1e-3, momentum=0.9, damping=1e-4):\n",
        "        params = list(model.parameters())\n",
        "        super().__init__(params, dict(lr=lr, momentum=momentum))\n",
        "\n",
        "        self.known_modules = {'Linear', 'Conv2d'}\n",
        "        self.modules = []\n",
        "        self.grad_outputs = {}\n",
        "        self.acc_stats = False\n",
        "\n",
        "        self._prepare_model(model)\n",
        "\n",
        "    def _save_input(self, module, input):\n",
        "        if self.acc_stats and module.training:\n",
        "            self.inputs[module] = input[0].data\n",
        "\n",
        "    def _save_grad_output(self, module, grad_input, grad_output):\n",
        "        if self.acc_stats and module.training:\n",
        "            self.grad_outputs[module] = grad_output[0].data\n",
        "\n",
        "    def _register_hook(self, module):\n",
        "        handle1 = module.register_forward_pre_hook(self._save_input)\n",
        "        handle2 = module.register_backward_hook(self._save_grad_output)\n",
        "        self.handles[module] = (handle1, handle2)\n",
        "\n",
        "    def _prepare_model(self, model):\n",
        "        self.modules = []\n",
        "        self.handles = {}\n",
        "\n",
        "        for module in model.modules():\n",
        "            class_name = module.__class__.__name__\n",
        "            if class_name in self.known_modules:\n",
        "                self.modules.append(module)\n",
        "                self._register_hook(module)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for module in self.modules:\n",
        "            if module not in self.grad_outputs:\n",
        "                continue\n",
        "\n",
        "            grad_out = self.grad_outputs[module]\n",
        "            grad_in = self.inputs[module]\n",
        "\n",
        "            g_g = grad_out.t() @ grad_out\n",
        "            a_a = grad_in.t() @ grad_in\n",
        "\n",
        "            if module not in self.state:\n",
        "                self.state[module] = {}\n",
        "            state = self.state[module]\n",
        "\n",
        "            mom = self.defaults['momentum']\n",
        "            damp = self.defaults['damping']\n",
        "\n",
        "            if 'g_g_mom' not in state:\n",
        "                state['g_g_mom'] = g_g.clone()\n",
        "                state['a_a_mom'] = a_a.clone()\n",
        "            else:\n",
        "                state['g_g_mom'].mul_(mom).add_(g_g)\n",
        "                state['a_a_mom'].mul_(mom).add_(a_a)\n",
        "\n",
        "            g_g_mom = state['g_g_mom']\n",
        "            a_a_mom = state['a_a_mom']\n",
        "\n",
        "            g_g_inv = (g_g_mom + damp * torch.eye(\n",
        "                g_g_mom.size(0), device=g_g_mom.device\n",
        "            )).inverse()\n",
        "            a_a_inv = (a_a_mom + damp * torch.eye(\n",
        "                a_a_mom.size(0), device=a_a_mom.device\n",
        "            )).inverse()\n",
        "\n",
        "            if module.weight.grad is not None:\n",
        "                weight_grad = module.weight.grad.reshape(\n",
        "                    -1, module.weight.size(0)\n",
        "                )\n",
        "                module.weight.grad = (\n",
        "                    g_g_inv @ weight_grad @ a_a_inv\n",
        "                ).reshape_as(module.weight)\n",
        "\n",
        "            if module.bias is not None and module.bias.grad is not None:\n",
        "                module.bias.grad = (g_g_inv @ module.bias.grad)\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "\n",
        "                param_state = self.state[p]\n",
        "                if 'momentum_buffer' not in param_state:\n",
        "                    buf = param_state['momentum_buffer'] = p.grad.clone()\n",
        "                else:\n",
        "                    buf = param_state['momentum_buffer']\n",
        "                    buf.mul_(group['momentum']).add_(p.grad)\n",
        "\n",
        "                p.data.add_(buf, alpha=-group['lr'])\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "CQawlt1o7K5H"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(model, config):\n",
        "    no_decay = ['bias', 'LayerNorm.weight']\n",
        "    grouped_params = [\n",
        "        {\n",
        "            'params': [p for n, p in model.named_parameters()\n",
        "                      if not any(nd in n for nd in no_decay)],\n",
        "            'weight_decay': config.WEIGHT_DECAY\n",
        "        },\n",
        "        {\n",
        "            'params': [p for n, p in model.named_parameters()\n",
        "                      if any(nd in n for nd in no_decay)],\n",
        "            'weight_decay': 0.0\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    opt = torch.optim.AdamW(grouped_params, lr=config.LEARNING_RATE)\n",
        "    return opt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OrdinalFocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=2.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.eps = 1e-6\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        # clamp for num stability\n",
        "        pred = torch.clamp(pred, self.eps, 1-self.eps)\n",
        "\n",
        "        # base l2 loss\n",
        "        diff = (pred - target) ** 2\n",
        "\n",
        "        # focal weight w/softmax normalization\n",
        "        pt = torch.exp(-diff) / torch.exp(-diff).sum()\n",
        "        focal_weight = (1 - pt) ** self.alpha\n",
        "\n",
        "        # entropy reg (bounded)\n",
        "        entropy = -(pred * torch.log(pred + self.eps)).mean()\n",
        "        entropy_reg = torch.clamp(0.5 - entropy, 0, 1)\n",
        "\n",
        "        # combine + scale\n",
        "        loss = (focal_weight * diff).mean() + 0.1 * entropy_reg\n",
        "        return torch.clamp(loss, 0, 100.0)  # prevent explosion"
      ],
      "metadata": {
        "id": "h2f6RKpmbFD4"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "obZDkeVM7K5H"
      },
      "outputs": [],
      "source": [
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, temperature=0.07):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, z1, z2):\n",
        "        z1 = F.normalize(z1, dim=1)\n",
        "        z2 = F.normalize(z2, dim=1)\n",
        "\n",
        "        # compute similarity matrix\n",
        "        logits = torch.mm(z1, z2.t()) / self.temperature\n",
        "\n",
        "        # positive pairs on diagonal\n",
        "        labels = torch.arange(z1.shape[0]).to(z1.device)\n",
        "\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pretrain_transform(x):\n",
        "    aug1 = torch.roll(x, shifts=random.randint(1, x.shape[-1]//4), dims=-1)\n",
        "    aug2 = x + torch.randn_like(x) * 0.01\n",
        "    return aug1, aug2"
      ],
      "metadata": {
        "id": "eMlF5K3oVdev"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "eaLGiEAg7K5H"
      },
      "outputs": [],
      "source": [
        "class SimpleTemporal(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, pred, true):\n",
        "        pred = F.normalize(pred, dim=-1)\n",
        "        true = F.normalize(true, dim=-1)\n",
        "\n",
        "        sim = F.cosine_similarity(pred, true)\n",
        "        loss = F.smooth_l1_loss(sim, torch.ones_like(sim))\n",
        "\n",
        "        loss = loss + 0.01 * (pred.pow(2).sum() + true.pow(2).sum())\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "kvC56ua97K5H"
      },
      "outputs": [],
      "source": [
        "class SlowCurriculum:\n",
        "    def __init__(self, epochs):\n",
        "        self.epochs = epochs\n",
        "        self.task_weights = {\n",
        "            'learning_stage': lambda e: min(1.0, e/10),\n",
        "            'region_activation': lambda e: min(0.5, e/10),\n",
        "            'temporal_pattern': lambda e: min(0.3, e/15)\n",
        "        }\n",
        "\n",
        "    def get_weights(self, epoch):\n",
        "        return {k: f(epoch) for k,f in self.task_weights.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "HbcNaJ-D7K5H"
      },
      "outputs": [],
      "source": [
        "class TemporalTransformer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.time_rnn = nn.LSTM(\n",
        "            config.EMBED_DIM,\n",
        "            config.EMBED_DIM//2,\n",
        "            bidirectional=True,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.time_norm = nn.LayerNorm(config.EMBED_DIM)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b,t,n,d = x.shape\n",
        "        x = x.reshape(b, t, -1)\n",
        "        x = self.time_rnn(x)[0]\n",
        "        x = self.time_norm(x)\n",
        "        return x.reshape(b, t, n, d)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "map bids fname -> learning stage"
      ],
      "metadata": {
        "id": "uNqALzvZVjoT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "o1R7uMD17K5I"
      },
      "outputs": [],
      "source": [
        "def get_learning_stage(f: Path) -> float:\n",
        "    fname = f.name\n",
        "\n",
        "    is_reversal = 'reversal' in fname\n",
        "    is_run2 = 'run-2' in fname\n",
        "\n",
        "    if not is_reversal:\n",
        "        return 0.25 if is_run2 else 0.0\n",
        "    else:\n",
        "        return 1.0 if is_run2 else 0.75"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "patience-based early stopping"
      ],
      "metadata": {
        "id": "_suwhij5Vs0Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "cCc88VSt7K5I"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "temporal cv w/purge+embargo periods"
      ],
      "metadata": {
        "id": "AH7Y-Za9VuJ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "IiLriDyJ7K5I"
      },
      "outputs": [],
      "source": [
        "class TimeSeriesCV:\n",
        "    def __init__(self, n_splits=5, purge=10, embargo=5):\n",
        "        self.n_splits = n_splits\n",
        "        self.purge = purge\n",
        "        self.embargo = embargo\n",
        "\n",
        "    def split(self, X, groups):\n",
        "        unique_groups = np.sort(np.unique(groups))\n",
        "        n_groups = len(unique_groups)\n",
        "        group_size = n_groups // self.n_splits\n",
        "\n",
        "        for i in range(self.n_splits):\n",
        "            test_start = i * group_size\n",
        "            test_end = test_start + group_size\n",
        "\n",
        "            train_idx = np.where(\n",
        "                (groups < unique_groups[max(0, test_start - self.embargo)]) |\n",
        "                (groups > unique_groups[min(n_groups-1, test_end + self.embargo)])\n",
        "            )[0]\n",
        "            test_idx = np.where(\n",
        "                (groups >= unique_groups[test_start]) &\n",
        "                (groups < unique_groups[test_end])\n",
        "            )[0]\n",
        "\n",
        "            yield train_idx, test_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "persist model state w/ validation metrics"
      ],
      "metadata": {
        "id": "rmjcQu-RVxa4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "27sQYGpw7K5I"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model, trainer, config, epoch):\n",
        "    ckpt_path = Path(config.CKPT_DIR) / f\"brain_vit_e{epoch}.pt\"\n",
        "\n",
        "    metrics = {\n",
        "        'epoch': epoch,\n",
        "        'learning_stage_mse': np.mean(trainer.metrics.get('val_mse', [])),\n",
        "        'region_mae': np.mean(trainer.metrics.get('val_mae', [])),\n",
        "        'temporal_corr': np.mean(trainer.metrics.get('val_corr', [])),\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        torch.save({\n",
        "            'model': model.state_dict(),\n",
        "            'metrics': metrics,\n",
        "            'config': {k:v for k,v in config.__dict__.items()\n",
        "                      if not k.startswith('_')}\n",
        "        }, ckpt_path)\n",
        "        print(f\"saved checkpoint to {ckpt_path}\")\n",
        "\n",
        "        latest = Path(config.CKPT_DIR) / \"brain_vit_latest.pt\"\n",
        "        if latest.exists():\n",
        "            latest.unlink()\n",
        "        latest.symlink_to(ckpt_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"failed to save checkpoint: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    return ckpt_path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "huber w/ dynamic threshold"
      ],
      "metadata": {
        "id": "uk_Gue-EV0wd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "I_BPbPdz7K5I"
      },
      "outputs": [],
      "source": [
        "class AdaptiveHuber(nn.Module):\n",
        "    def __init__(self, beta=0.1):\n",
        "        super().__init__()\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, pred, true):\n",
        "        error = torch.abs(pred - true)\n",
        "        c = self.beta * error.detach().median()\n",
        "        quad = 0.5 * error.pow(2) / c\n",
        "        linear = error - 0.5 * c\n",
        "        return torch.where(error <= c, quad, linear).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "MbkM2OkF7K5I"
      },
      "outputs": [],
      "source": [
        "class FocalRegion(nn.Module):\n",
        "    def __init__(self, alpha=2.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, pred, true):\n",
        "        diff = torch.abs(pred - true)\n",
        "        weight = (1 - torch.exp(-diff)).pow(self.alpha)\n",
        "        return (weight * diff).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "3Yn8hFJB7K5I"
      },
      "outputs": [],
      "source": [
        "class GaussianTemporal(nn.Module):\n",
        "    def __init__(self, sigma=0.1):\n",
        "        super().__init__()\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def forward(self, pred, true):\n",
        "        pred = F.normalize(pred, dim=-1)\n",
        "        true = F.normalize(true, dim=-1)\n",
        "\n",
        "        dist = torch.cdist(pred.unsqueeze(0), true.unsqueeze(0)).squeeze()\n",
        "        kernel = torch.exp(-dist.pow(2) / (2 * self.sigma**2))\n",
        "\n",
        "        return -torch.log(kernel.diag() + 1e-6).mean()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def time_split(dataset, n_splits=5):\n",
        "    indices = np.arange(len(dataset))\n",
        "    split_size = len(indices) // n_splits\n",
        "\n",
        "    for i in range(n_splits):\n",
        "        mask = np.ones(len(dataset), dtype=bool)\n",
        "        start_idx = i * split_size\n",
        "        end_idx = start_idx + split_size\n",
        "        mask[start_idx:end_idx] = False\n",
        "\n",
        "        train_idx = indices[mask]\n",
        "        val_idx = indices[~mask]\n",
        "        yield train_idx, val_idx"
      ],
      "metadata": {
        "id": "ynyNCEw7YjFF"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "5Y_WJJej7K5I"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import entropy as scipy_entropy\n",
        "from scipy.stats import ks_2samp\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, config):\n",
        "        self.model = model.cuda()\n",
        "        self.config = config\n",
        "\n",
        "        self.opt = torch.optim.AdamW(\n",
        "            model.parameters(),\n",
        "            lr=config.LEARNING_RATE,\n",
        "            weight_decay=0.1\n",
        "        )\n",
        "\n",
        "        self.sched = get_cosine_schedule_with_warmup(\n",
        "            self.opt,\n",
        "            config.WARMUP_EPOCHS * 5,\n",
        "            config.NUM_EPOCHS * 5\n",
        "        )\n",
        "\n",
        "        self.criterion = WeightedMultiTaskLoss(device='cuda')\n",
        "        self.scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.plateau_counter = 0\n",
        "        self.metrics = defaultdict(list)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validate(self, val_loader):\n",
        "        self.model.eval()\n",
        "        stats = defaultdict(list)\n",
        "        pred_list, label_list = [], []\n",
        "\n",
        "        for batch in val_loader:\n",
        "            x = batch[0].cuda(non_blocking=True)\n",
        "            task_ids = batch[1].cuda(non_blocking=True)\n",
        "            targets = {k: v.cuda(non_blocking=True)\n",
        "                      for k,v in batch[2].items()}\n",
        "\n",
        "            outputs = self.model(x, task_ids)\n",
        "            loss, batch_stats = self.criterion(outputs, targets)\n",
        "\n",
        "            stats['val_loss'].append(loss.item())\n",
        "            for k,v in batch_stats.items():\n",
        "                stats[f'val_{k}'].append(v)\n",
        "\n",
        "            pred_list.append(outputs['learning_stage'].cpu().squeeze())\n",
        "            label_list.append(targets['learning_stage'].cpu())\n",
        "\n",
        "        preds = torch.cat(pred_list)\n",
        "        labels = torch.cat(label_list)\n",
        "\n",
        "        # distribution stats\n",
        "        pred_hist = torch.histc(preds, bins=4, min=0, max=1)\n",
        "        label_hist = torch.histc(labels, bins=4, min=0, max=1)\n",
        "\n",
        "        stats['pred_entropy'] = scipy_entropy(pred_hist/len(preds))\n",
        "        stats['label_entropy'] = scipy_entropy(label_hist/len(labels))\n",
        "        stats['ks_stat'] = ks_2samp(preds, labels).statistic\n",
        "\n",
        "        return {k: np.mean(v) if isinstance(v, list) else v\n",
        "                for k,v in stats.items()}\n",
        "\n",
        "    def train_epoch(self, train_loader, epoch):\n",
        "        self.model.train()\n",
        "        stats = defaultdict(list)\n",
        "\n",
        "        with tqdm(train_loader) as pbar:\n",
        "            for batch in pbar:\n",
        "                x = batch[0].cuda(non_blocking=True)\n",
        "                task_ids = batch[1].cuda(non_blocking=True)\n",
        "                targets = {k: v.squeeze().cuda(non_blocking=True)\n",
        "                          for k,v in batch[2].items()}\n",
        "\n",
        "                if epoch > 5:\n",
        "                    x, targets['learning_stage'] = mixup(x, targets['learning_stage'])\n",
        "\n",
        "                with torch.amp.autocast(device_type='cuda'):\n",
        "                    outputs = self.model(x, task_ids)\n",
        "                    loss, batch_stats = self.criterion(outputs, targets)\n",
        "\n",
        "                self.opt.zero_grad()\n",
        "                self.scaler.scale(loss).backward()\n",
        "\n",
        "                self.scaler.unscale_(self.opt)\n",
        "                torch.nn.utils.clip_grad_norm_(\n",
        "                    self.model.parameters(),\n",
        "                    0.5  # hardcoded clip for stability\n",
        "                )\n",
        "\n",
        "                self.scaler.step(self.opt)\n",
        "                self.scaler.update()\n",
        "                self.sched.step()\n",
        "\n",
        "                stats['loss'].append(loss.item())\n",
        "                for k,v in batch_stats.items():\n",
        "                    stats[k].append(v)\n",
        "\n",
        "                pbar.set_postfix({\n",
        "                    'loss': f\"{loss.item():.3f}\",\n",
        "                    'lr': f\"{self.sched.get_last_lr()[0]:.2e}\"\n",
        "                })\n",
        "\n",
        "        return {k: np.mean(v) for k,v in stats.items()}\n",
        "\n",
        "    def train(self, train_loader, val_loader):\n",
        "        for epoch in range(self.config.NUM_EPOCHS):\n",
        "            train_stats = self.train_epoch(train_loader, epoch)\n",
        "            val_stats = self.validate(val_loader)\n",
        "\n",
        "            print(f\"\\nepoch {epoch}:\")\n",
        "            print(\"train:\", \" | \".join(f\"{k}: {v:.3f}\" for k,v in train_stats.items()))\n",
        "            print(\"val:\", \" | \".join(f\"{k}: {v:.3f}\" for k,v in val_stats.items()))\n",
        "\n",
        "            if val_stats['val_loss'] < self.best_val_loss:\n",
        "                self.best_val_loss = val_stats['val_loss']\n",
        "                self.plateau_counter = 0\n",
        "                if val_stats['ks_stat'] < 0.3:\n",
        "                    torch.save({\n",
        "                        'epoch': epoch,\n",
        "                        'model': self.model.state_dict(),\n",
        "                        'opt': self.opt.state_dict(),\n",
        "                        'stats': val_stats\n",
        "                    }, f\"{self.config.CKPT_DIR}/model_e{epoch}.pt\")\n",
        "            else:\n",
        "                self.plateau_counter += 1\n",
        "\n",
        "            if self.plateau_counter >= self.config.PATIENCE:\n",
        "                print(f\"stopping @ epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "            for k,v in {**train_stats, **val_stats}.items():\n",
        "                self.metrics[k].append(v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7jA0wOm7K5I"
      },
      "source": [
        "## Train Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "8BAEmrlw7K5I"
      },
      "outputs": [],
      "source": [
        "def init_dirs(config):\n",
        "    \"\"\"ensure cache exists\"\"\"\n",
        "    Path(config.CACHE).mkdir(parents=True, exist_ok=True)\n",
        "    Path(config.CKPT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "    return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "E9d9bFxM7K5I"
      },
      "outputs": [],
      "source": [
        "config = init_dirs(Config())\n",
        "data_config = DataConfig()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "tInbMGkS7K5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ddfde3-3cf8-4b29-c98b-ad5a64a7fe65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checking ds000002 at: /content/drive/MyDrive/learnedSpectrum/ds000002\n",
            "checking ds000011 at: /content/drive/MyDrive/learnedSpectrum/ds000011\n",
            "checking ds000017 at: /content/drive/MyDrive/learnedSpectrum/ds000017\n",
            "checking ds000052 at: /content/drive/MyDrive/learnedSpectrum/ds000052\n",
            "checking ds000002 at: /content/drive/MyDrive/learnedSpectrum/ds000002\n",
            "checking ds000011 at: /content/drive/MyDrive/learnedSpectrum/ds000011\n",
            "checking ds000017 at: /content/drive/MyDrive/learnedSpectrum/ds000017\n",
            "checking ds000052 at: /content/drive/MyDrive/learnedSpectrum/ds000052\n"
          ]
        }
      ],
      "source": [
        "manager = DatasetManager(data_config)\n",
        "manager.fetch_datasets()\n",
        "files = manager.get_all_files()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "bCLQ9bw07K5I"
      },
      "outputs": [],
      "source": [
        "learning_stage_labels = {}\n",
        "for ds_id, ds_files in files.items():\n",
        "    stage_map = manager.DATASETS[ds_id]['stage_map']\n",
        "    learning_stage_labels.update({\n",
        "        f.parts[-3]: float(stage_map(f))\n",
        "        for f in ds_files\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "7aM1QVOt7K5I"
      },
      "outputs": [],
      "source": [
        "model = SequentialBrainViT(config).cuda()\n",
        "criterion = WeightedMultiTaskLoss(device='cuda')\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=1e-4,\n",
        "    weight_decay=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "9nFMNEew7K5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25e2c76e-41a1-4d88-e667-a3e986132301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mock stages: {'sub-01': 0.0, 'sub-02': 0.25, 'sub-03': 0.5, 'sub-04': 0.75, 'sub-05': 1.0}\n"
          ]
        }
      ],
      "source": [
        "mock_labels = get_mock_labels()\n",
        "print(f\"mock stages: {mock_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "d5HGOG_s7K5I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "ad669674-f869-49c0-b0b6-a6bdbcb19292"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-1d78d1575c92>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFMRIDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-90-e9d6eaf6f188>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, tr, n_timepoints, n_regions, validate, cache_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     ):\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBIDSManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_timepoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_timepoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-5a0fea4c7482>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_id, path)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fetch_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-5a0fea4c7482>\u001b[0m in \u001b[0;36m_fetch_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8192\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    947\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0mflush_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# StringIO doesn't like amt=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def _raw_read(\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 \u001b[0;31m# clip the read to the \"end of response\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0mamt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "dataset = FMRIDataset()\n",
        "train_loader, val_loader = create_dataloaders(dataset, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "hxuNbqUE7K5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0bb1a0f-1a57-4081-d92b-91c70a39f188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-144-f93f66771f8f>:26: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(model, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "4gRFiEag7K5J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "aa58f940-c630-44e8-916f-9ef78f316e2e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "SequentialBrainViT.forward() takes 2 positional arguments but 3 were given",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-153-fdb93bdbdda1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtask_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: SequentialBrainViT.forward() takes 2 positional arguments but 3 were given"
          ]
        }
      ],
      "source": [
        "for batch in train_loader:\n",
        "    x, task_ids, targets = batch\n",
        "    x = x.to(device)\n",
        "    task_ids = task_ids.to(device)\n",
        "    outputs = model(x, task_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD-2Hu8L7K5J"
      },
      "outputs": [],
      "source": [
        "trainer.train(train_loader, val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FKAxrdN7K5J"
      },
      "source": [
        "## Inference Utils & Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-WPL59w7K5J"
      },
      "outputs": [],
      "source": [
        "def extract_training_stats(model, val_loader, config):\n",
        "    param_count = sum(p.numel() for p in model.parameters())\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    layer_norms = defaultdict(list)\n",
        "    grad_norms = defaultdict(list)\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.grad is not None:\n",
        "            layer_norms[name.split('.')[0]].append(param.norm().item())\n",
        "            grad_norms[name.split('.')[0]].append(param.grad.norm().item())\n",
        "\n",
        "    model.eval()\n",
        "    metrics = defaultdict(list)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            x = batch[0].to(config.device)\n",
        "            task_ids = batch[1].to(config.device)\n",
        "            targets = batch[2]\n",
        "            outputs = model(x, task_ids)\n",
        "\n",
        "            stage_pred = outputs['learning_stage'].cpu().numpy()\n",
        "            stage_true = targets['learning_stage'].numpy()\n",
        "            metrics['stage_mse'].append(np.mean((stage_pred - stage_true)**2))\n",
        "\n",
        "            region_pred = outputs['region_activation'].cpu().numpy()\n",
        "            region_true = targets['region_activation'].numpy()\n",
        "            metrics['region_mae'].append(np.mean(np.abs(region_pred - region_true)))\n",
        "\n",
        "            temp_pred = outputs['temporal_pattern'].cpu().numpy()\n",
        "            temp_true = targets['temporal_pattern'].numpy()\n",
        "            temp_corr = np.array([np.corrcoef(p,t)[0,1] for p,t in zip(temp_pred, temp_true)])\n",
        "            metrics['temp_corr'].append(np.mean(temp_corr))\n",
        "\n",
        "    print(\"\\nmodel architecture:\")\n",
        "    print(f\"total params: {param_count:,}\")\n",
        "    print(f\"trainable params: {trainable:,}\")\n",
        "\n",
        "    print(\"\\nlayer statistics:\")\n",
        "    for layer in layer_norms:\n",
        "        print(f\"{layer:20} weight_norm: {np.mean(layer_norms[layer]):.3f}  grad_norm: {np.mean(grad_norms[layer]):.3e}\")\n",
        "\n",
        "    print(\"\\nvalidation metrics:\")\n",
        "    for k,v in metrics.items():\n",
        "        print(f\"{k:15} {np.mean(v):.3f}  {np.std(v):.3f}\")\n",
        "\n",
        "    return {\n",
        "        'architecture': {\n",
        "            'total_params': param_count,\n",
        "            'trainable_params': trainable\n",
        "        },\n",
        "        'layer_stats': {\n",
        "            k: {\n",
        "                'weight_norm': np.mean(v),\n",
        "                'grad_norm': np.mean(grad_norms[k])\n",
        "            } for k,v in layer_norms.items()\n",
        "        },\n",
        "        'val_metrics': {\n",
        "            k: {'mean': np.mean(v), 'std': np.std(v)}\n",
        "            for k,v in metrics.items()\n",
        "        }\n",
        "    }\n",
        "\n",
        "stats = extract_training_stats(model, val_loader, config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_stage_confusion(model, val_loader, config):\n",
        "    import numpy as np\n",
        "    import seaborn as sns\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "    true_stages = []\n",
        "    pred_stages = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            x = batch[0].to(config.device)\n",
        "            task_ids = batch[1].to(config.device)\n",
        "            targets = batch[2]\n",
        "\n",
        "            outputs = model(x, task_ids)\n",
        "\n",
        "            pred = outputs['learning_stage'].cpu().numpy()\n",
        "            true = targets['learning_stage'].numpy()\n",
        "\n",
        "            pred_disc = np.digitize(pred, bins=[0.25, 0.5, 0.75])\n",
        "            true_disc = np.digitize(true, bins=[0.25, 0.5, 0.75])\n",
        "\n",
        "            true_stages.extend(true_disc)\n",
        "            pred_stages.extend(pred_disc)\n",
        "\n",
        "    cm = confusion_matrix(true_stages, pred_stages, normalize='true')\n",
        "\n",
        "    plt.figure(figsize=(10,8))\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='RdYlBu_r',\n",
        "                xticklabels=['naive', 'early', 'intermediate', 'advanced'],\n",
        "                yticklabels=['naive', 'early', 'intermediate', 'advanced'])\n",
        "    plt.title('learning stage confusion matrix (normalized)')\n",
        "    plt.xlabel('predicted stage')\n",
        "    plt.ylabel('true stage')\n",
        "\n",
        "    diag = np.diag(cm)\n",
        "    acc = diag.mean()\n",
        "    misclass = 1 - acc\n",
        "\n",
        "    print(f\"\\nconfusion matrix analysis:\")\n",
        "    print(f\"accuracy: {acc:.3f}\")\n",
        "    print(f\"misclassification: {misclass:.3f}\")\n",
        "    print(f\"per-stage accuracy:\", {stage: f\"{acc:.3f}\" for stage, acc in\n",
        "                                 zip(['naive', 'early', 'inter', 'adv'], diag)})\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return {\n",
        "        'confusion_matrix': cm,\n",
        "        'accuracy': acc,\n",
        "        'misclassification': misclass,\n",
        "        'per_stage_accuracy': dict(zip(['naive', 'early', 'inter', 'adv'], diag))\n",
        "    }\n",
        "\n",
        "results = plot_learning_stage_confusion(model, val_loader, config)"
      ],
      "metadata": {
        "id": "iOSg3qkg5-rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_comprehensive_analysis(model, val_loader):\n",
        "    def temporal_analysis():\n",
        "        x, task_ids, targets = next(iter(val_loader))\n",
        "        x = x.to(model.device)\n",
        "        task_ids = task_ids.to(model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = model(x, task_ids)\n",
        "\n",
        "        plt.figure(figsize=(15,10))\n",
        "\n",
        "        plt.subplot(2,2,1)\n",
        "        for i in range(min(4, len(targets['temporal_pattern']))):\n",
        "            true = targets['temporal_pattern'][i].numpy()\n",
        "            pred = preds['temporal_pattern'][i].cpu().numpy()\n",
        "            if not np.any(np.isnan(true)) and not np.any(np.isnan(pred)):\n",
        "                plt.plot(true, f'C{i}-', label=f'true_{i}', alpha=0.7)\n",
        "                plt.plot(pred, f'C{i}--', label=f'pred_{i}', alpha=0.7)\n",
        "        plt.title('temporal dynamics')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(2,2,2)\n",
        "        true_flat = targets['temporal_pattern'].numpy().reshape(-1)\n",
        "        pred_flat = preds['temporal_pattern'].cpu().numpy().reshape(-1)\n",
        "        mask = ~np.isnan(true_flat) & ~np.isnan(pred_flat)\n",
        "        if mask.any():\n",
        "            plt.scatter(true_flat[mask], pred_flat[mask], alpha=0.5)\n",
        "            plt.plot([-2,2], [-2,2], 'r--', alpha=0.5)  # standardized range\n",
        "        plt.xlabel('true')\n",
        "        plt.ylabel('pred')\n",
        "        plt.title('temporal correlation')\n",
        "\n",
        "        plt.subplot(2,2,3)\n",
        "        errors = pred_flat[mask] - true_flat[mask] if mask.any() else np.array([])\n",
        "        if len(errors):\n",
        "            sns.histplot(errors, kde=True)\n",
        "            plt.axvline(0, color='r', linestyle='--', alpha=0.5)\n",
        "            plt.title(f'error dist (={errors.mean():.3f}, ={errors.std():.3f})')\n",
        "\n",
        "        plt.subplot(2,2,4)\n",
        "        if mask.any():\n",
        "            f_true, Pxx_true = signal.welch(true_flat[mask], fs=1.0/2.0)\n",
        "            f_pred, Pxx_pred = signal.welch(pred_flat[mask], fs=1.0/2.0)\n",
        "            plt.semilogy(f_true, Pxx_true, label='true', alpha=0.7)\n",
        "            plt.semilogy(f_pred, Pxx_pred, label='pred', alpha=0.7)\n",
        "            plt.title('power spectra')\n",
        "            plt.xlabel('freq (hz)')\n",
        "            plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def attention_analysis():\n",
        "        x, task_ids, _ = next(iter(val_loader))\n",
        "        x = x.to(model.device)\n",
        "        task_ids = task_ids.to(model.device)\n",
        "\n",
        "        attn_maps = []\n",
        "        def hook_fn(module, input, output):\n",
        "            attn = output[1].detach().cpu()[0]\n",
        "            if not torch.isnan(attn).any():\n",
        "                attn_maps.append(attn)\n",
        "\n",
        "        hooks = []\n",
        "        for block in model.blocks:\n",
        "            hooks.append(block.attn.register_forward_hook(hook_fn))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model(x, task_ids)\n",
        "        for h in hooks:\n",
        "            h.remove()\n",
        "\n",
        "        if not attn_maps:\n",
        "            print(\"no valid attention maps found\")\n",
        "            return\n",
        "\n",
        "        plt.figure(figsize=(20,5))\n",
        "        for i, attn in enumerate(attn_maps):\n",
        "            plt.subplot(1, len(attn_maps), i+1)\n",
        "            attn_viz = attn.reshape(1281, -1) if len(attn.shape) == 1 else attn\n",
        "            plt.imshow(attn_viz.numpy(), aspect='auto', cmap='RdBu_r')\n",
        "            plt.title(f'L{i+1}')\n",
        "            if i == 0:\n",
        "                plt.ylabel('query')\n",
        "            plt.xlabel('key')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        if len(attn_maps) > 1:\n",
        "            plt.figure(figsize=(15,5))\n",
        "            plt.subplot(131)\n",
        "            means = [attn.mean().item() for attn in attn_maps]\n",
        "            plt.plot(means, 'o-')\n",
        "            plt.title('mean attention')\n",
        "            plt.xlabel('layer')\n",
        "\n",
        "            plt.subplot(132)\n",
        "            sparsity = [(attn < 0.1).float().mean().item() for attn in attn_maps]\n",
        "            plt.plot(sparsity, 'o-')\n",
        "            plt.title('sparsity')\n",
        "            plt.xlabel('layer')\n",
        "\n",
        "            plt.subplot(133)\n",
        "            valid_eigs = []\n",
        "            for attn in attn_maps:\n",
        "                try:\n",
        "                    eigs = torch.linalg.eigvalsh(attn)[-5:]\n",
        "                    if not torch.isnan(eigs).any():\n",
        "                        valid_eigs.append(eigs)\n",
        "                except:\n",
        "                    continue\n",
        "            if valid_eigs:\n",
        "                plt.plot(torch.stack(valid_eigs).cpu().numpy())\n",
        "                plt.title('top-5 eigenvalues')\n",
        "                plt.xlabel('layer')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "    def network_analysis():\n",
        "        param_norms = []\n",
        "        grad_norms = []\n",
        "        names = []\n",
        "\n",
        "        for name, p in model.named_parameters():\n",
        "            if p.requires_grad and not torch.isnan(p).any():\n",
        "                param_norms.append(p.norm().item())\n",
        "                if p.grad is not None and not torch.isnan(p.grad).any():\n",
        "                    grad_norms.append(p.grad.norm().item())\n",
        "                    names.append(name.split('.')[0])\n",
        "\n",
        "        if not names:\n",
        "            print(\"no valid params found\")\n",
        "            return\n",
        "\n",
        "        plt.figure(figsize=(10,5))\n",
        "\n",
        "        plt.subplot(121)\n",
        "        if len(param_norms) > 1:\n",
        "            sns.boxplot(x=names, y=param_norms)\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.title('param norms')\n",
        "\n",
        "        plt.subplot(122)\n",
        "        if len(grad_norms) > 1:\n",
        "            sns.boxplot(x=names, y=grad_norms)\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.title('grad norms')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    print(\"temporal:\")\n",
        "    temporal_analysis()\n",
        "    print(\"\\nattention:\")\n",
        "    attention_analysis()\n",
        "    print(\"\\nnetwork:\")\n",
        "    network_analysis()\n",
        "\n",
        "plot_comprehensive_analysis(model, val_loader)"
      ],
      "metadata": {
        "id": "yuA1DtZxJjYt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}