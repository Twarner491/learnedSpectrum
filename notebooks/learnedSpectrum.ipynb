{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fMRI Learning Stage Classification with Vision Transformers\n",
    "\n",
    "This notebook demonstrates the use of Vision Transformers for classifying different stages of learning from fMRI data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/twarn/Repositories/learnedSpectrum\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (0.20.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (2.1.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (2.2.3)\n",
      "Requirement already satisfied: nibabel in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (5.3.2)\n",
      "Requirement already satisfied: nilearn in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (0.11.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (1.5.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (4.46.3)\n",
      "Requirement already satisfied: wandb in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (0.18.7)\n",
      "Requirement already satisfied: lru-dict in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: pywavelets in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (1.7.0)\n",
      "Requirement already satisfied: einops in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (0.8.0)\n",
      "Requirement already satisfied: timm in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (1.0.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (4.67.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (1.14.1)\n",
      "Requirement already satisfied: requests in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torch>=2.0->learnedSpectrum==0.1.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torch>=2.0->learnedSpectrum==0.1.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torch>=2.0->learnedSpectrum==0.1.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torch>=2.0->learnedSpectrum==0.1.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torch>=2.0->learnedSpectrum==0.1.0) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torch>=2.0->learnedSpectrum==0.1.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->learnedSpectrum==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-resources>=5.12 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from nibabel->learnedSpectrum==0.1.0) (6.4.5)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from nibabel->learnedSpectrum==0.1.0) (24.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from nilearn->learnedSpectrum==0.1.0) (1.4.2)\n",
      "Requirement already satisfied: lxml in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from nilearn->learnedSpectrum==0.1.0) (5.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from pandas->learnedSpectrum==0.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from pandas->learnedSpectrum==0.1.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from pandas->learnedSpectrum==0.1.0) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from requests->learnedSpectrum==0.1.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from requests->learnedSpectrum==0.1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from requests->learnedSpectrum==0.1.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from requests->learnedSpectrum==0.1.0) (2024.8.30)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from scikit-learn->learnedSpectrum==0.1.0) (3.5.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from timm->learnedSpectrum==0.1.0) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from timm->learnedSpectrum==0.1.0) (0.26.3)\n",
      "Requirement already satisfied: safetensors in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from timm->learnedSpectrum==0.1.0) (0.4.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torchvision->learnedSpectrum==0.1.0) (11.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from tqdm->learnedSpectrum==0.1.0) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from transformers->learnedSpectrum==0.1.0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from transformers->learnedSpectrum==0.1.0) (0.20.3)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (5.29.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (6.1.0)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (2.19.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (1.3.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (65.5.0)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb->learnedSpectrum==0.1.0) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->learnedSpectrum==0.1.0) (4.0.11)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from jinja2->torch>=2.0->learnedSpectrum==0.1.0) (3.0.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->learnedSpectrum==0.1.0) (5.0.1)\n",
      "Building wheels for collected packages: learnedSpectrum\n",
      "  Building editable for learnedSpectrum (pyproject.toml): started\n",
      "  Building editable for learnedSpectrum (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for learnedSpectrum: filename=learnedSpectrum-0.1.0-0.editable-py3-none-any.whl size=7781 sha256=8eb76637771e029af74ac664b54a42a9a3b568603a9051a5d82472a0cff79e35\n",
      "  Stored in directory: C:\\Users\\twarn\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-aanoo8l4\\wheels\\df\\e2\\01\\25b890ddbee843adacdabb258984995d70b3d4b4901a7c5b3a\n",
      "Successfully built learnedSpectrum\n",
      "Installing collected packages: learnedSpectrum\n",
      "  Attempting uninstall: learnedSpectrum\n",
      "    Found existing installation: learnedSpectrum 0.1.0\n",
      "    Uninstalling learnedSpectrum-0.1.0:\n",
      "      Successfully uninstalled learnedSpectrum-0.1.0\n",
      "Successfully installed learnedSpectrum-0.1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Install package in editable mode if not already installed\n",
    "!pip install -e {project_root}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "from learnedSpectrum.config import Config, DataConfig\n",
    "from learnedSpectrum.data import DatasetManager, create_dataloaders\n",
    "from learnedSpectrum.train import VisionTransformerModel, train_one_epoch, evaluate\n",
    "from learnedSpectrum.visualization import VisualizationManager\n",
    "from learnedSpectrum.utils import (\n",
    "    seed_everything,\n",
    "    get_optimizer,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    save_checkpoint,\n",
    "    calculate_metrics,\n",
    "    verify_model_devices\n",
    ")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: tawarner (tawarner-usc). Use `wandb login --relogin` to force relogin\n",
      "wandb: WARNING Path C:\\Users\\twarn\\Repositories\\wandb\\wandb\\ wasn't writable, using system temp directory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\twarn\\AppData\\Local\\Temp\\wandb\\run-20241202_231239-8ozzeugv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tawarner-usc/fmri-learning-stages/runs/8ozzeugv' target=\"_blank\">robust-sun-46</a></strong> to <a href='https://wandb.ai/tawarner-usc/fmri-learning-stages' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tawarner-usc/fmri-learning-stages' target=\"_blank\">https://wandb.ai/tawarner-usc/fmri-learning-stages</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tawarner-usc/fmri-learning-stages/runs/8ozzeugv' target=\"_blank\">https://wandb.ai/tawarner-usc/fmri-learning-stages/runs/8ozzeugv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize configurations\n",
    "config = Config()\n",
    "data_config = DataConfig()\n",
    "\n",
    "# Set up visualization\n",
    "viz = VisualizationManager(save_dir=Path(config.ROOT) / \"visualizations\")\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(\n",
    "    project='fmri-learning-stages',\n",
    "    config=vars(config),\n",
    "    dir=Path(config.ROOT) / \"wandb\"\n",
    ")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Preparing datasets...\n",
      "INFO:learnedSpectrum.data:splits: train=237, val=31, test=30\n",
      "INFO:__main__:Dataset sizes - Train: 237, Val: 31, Test: 30\n"
     ]
    }
   ],
   "source": [
    "# Initialize dataset manager\n",
    "dataset_manager = DatasetManager(config, data_config)\n",
    "\n",
    "# Prepare datasets\n",
    "logger.info(\"Preparing datasets...\")\n",
    "train_dataset, val_dataset, test_dataset = dataset_manager.prepare_datasets()\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    train_dataset, val_dataset, test_dataset, config\n",
    ")\n",
    "\n",
    "logger.info(f\"Dataset sizes - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and visualize a sample\n",
    "sample_volume, sample_label = train_dataset[0]\n",
    "viz.plot_brain_slice(\n",
    "    volume=sample_volume.numpy(),\n",
    "    title=f'Sample Brain Slice (Learning Stage: {sample_label})',\n",
    "    save_name='sample_slice'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:learnedSpectrum.utils:model on: cuda:0\n",
      "C:\\Users\\twarn\\AppData\\Local\\Temp\\ipykernel_30500\\1377333977.py:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=config.USE_AMP)\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = VisionTransformerModel(config)\n",
    "verify_model_devices(model)\n",
    "\n",
    "# Setup training components\n",
    "optimizer = get_optimizer(model, config)\n",
    "scaler = GradScaler(enabled=config.USE_AMP)\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=config.WARMUP_EPOCHS * len(train_loader),\n",
    "    num_training_steps=config.NUM_EPOCHS * len(train_loader)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loader lens: train=15, val=2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'create_dataloaders.<locals>.collate_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloader lens: train=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch peek: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mNUM_EPOCHS):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:484\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:415\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1138\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1131\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1138\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\popen_spawn_win32.py:94\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 94\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'create_dataloaders.<locals>.collate_fn'"
     ]
    }
   ],
   "source": [
    "# Training history\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(f\"loader lens: train={len(train_loader)}, val={len(val_loader)}\")\n",
    "print(f\"batch peek: {next(iter(train_loader))[0].shape}\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(config.NUM_EPOCHS):\n",
    "    logger.info(f\"\\nEpoch {epoch + 1}/{config.NUM_EPOCHS}\")\n",
    "    \n",
    "    # Training phase\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, scaler, config)\n",
    "    train_loss, train_metrics = evaluate(model, train_loader, config)\n",
    "    \n",
    "    # Validation phase\n",
    "    val_loss, val_metrics = evaluate(model, val_loader, config)\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_metrics['accuracy'])\n",
    "    history['val_acc'].append(val_metrics['accuracy'])\n",
    "    \n",
    "    # Plot training progress\n",
    "    viz.plot_training_history(history, save_name=f'training_history_epoch_{epoch}')\n",
    "    \n",
    "    # Log to wandb\n",
    "    viz.log_to_wandb({\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'train_metrics': train_metrics,\n",
    "        'val_metrics': val_metrics,\n",
    "        'learning_rate': optimizer.param_groups[0]['lr']\n",
    "    }, epoch)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        save_checkpoint(\n",
    "            model, optimizer, epoch, val_loss, config,\n",
    "            filename=f\"best_model_epoch_{epoch}.pth\"\n",
    "        )\n",
    "        \n",
    "    logger.info(\n",
    "        f\"Epoch {epoch + 1} - \"\n",
    "        f\"Train Loss: {train_loss:.4f}, \"\n",
    "        f\"Train Acc: {train_metrics['accuracy']:.4f}, \"\n",
    "        f\"Val Loss: {val_loss:.4f}, \"\n",
    "        f\"Val Acc: {val_metrics['accuracy']:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_path = Path(config.CKPT_DIR) / \"best_model.pth\"\n",
    "model, _, _ = load_checkpoint(model, None, best_model_path)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_metrics = evaluate(model, test_loader, config)\n",
    "logger.info(f\"\\nTest Results - Loss: {test_loss:.4f}, Accuracy: {test_metrics['accuracy']:.4f}, AUC: {test_metrics['auc']:.4f}\")\n",
    "\n",
    "# Get predictions for visualization\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "all_probs = np.array(all_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "viz.plot_confusion_matrix(\n",
    "    y_true=all_labels,\n",
    "    y_pred=all_preds,\n",
    "    classes=['Early', 'Middle', 'Late', 'Mastery'],\n",
    "    save_name='confusion_matrix'\n",
    ")\n",
    "\n",
    "# Plot ROC curves\n",
    "viz.plot_roc_curves(\n",
    "    y_true=all_labels,\n",
    "    y_scores=all_probs,\n",
    "    classes=['Early', 'Middle', 'Late', 'Mastery'],\n",
    "    save_name='roc_curves'\n",
    ")\n",
    "\n",
    "# Visualize attention maps for a sample\n",
    "sample_input = next(iter(test_loader))[0][:1].to(device)\n",
    "with torch.no_grad():\n",
    "    attention_weights = model.vit.get_attention_weights(sample_input)\n",
    "\n",
    "viz.plot_attention_map(\n",
    "    attention_weights=attention_weights[0].cpu(),  # First head's attention\n",
    "    volume_shape=config.VOLUME_SIZE,\n",
    "    save_name='attention_map'\n",
    ")\n",
    "\n",
    "# Save final results to wandb\n",
    "wandb.log({\n",
    "    'final_test_loss': test_loss,\n",
    "    'final_test_accuracy': test_metrics['accuracy'],\n",
    "    'final_test_auc': test_metrics['auc'],\n",
    "    'confusion_matrix': wandb.Image(str(viz.save_dir / 'confusion_matrix.png')),\n",
    "    'roc_curves': wandb.Image(str(viz.save_dir / 'roc_curves.png')),\n",
    "    'attention_map': wandb.Image(str(viz.save_dir / 'attention_map.png'))\n",
    "})\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
