{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fMRI Learning Stage Classification with Vision Transformers\n",
    "\n",
    "This notebook demonstrates the use of Vision Transformers for classifying different stages of learning from fMRI data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/twarn/Repositories/learnedSpectrum\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (0.20.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (2.1.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (2.2.3)\n",
      "Requirement already satisfied: nibabel in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (5.3.2)\n",
      "Requirement already satisfied: nilearn in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (0.11.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (1.5.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (4.46.3)\n",
      "Requirement already satisfied: wandb in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (0.18.7)\n",
      "Requirement already satisfied: lru-dict in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: pywavelets in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (1.7.0)\n",
      "Requirement already satisfied: einops in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (0.8.0)\n",
      "Requirement already satisfied: timm in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (1.0.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (4.67.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (1.14.1)\n",
      "Requirement already satisfied: requests in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torch>=2.0->learnedSpectrum==0.1.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torch>=2.0->learnedSpectrum==0.1.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torch>=2.0->learnedSpectrum==0.1.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torch>=2.0->learnedSpectrum==0.1.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torch>=2.0->learnedSpectrum==0.1.0) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torch>=2.0->learnedSpectrum==0.1.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->learnedSpectrum==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-resources>=5.12 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from nibabel->learnedSpectrum==0.1.0) (6.4.5)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from nibabel->learnedSpectrum==0.1.0) (24.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from nilearn->learnedSpectrum==0.1.0) (1.4.2)\n",
      "Requirement already satisfied: lxml in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from nilearn->learnedSpectrum==0.1.0) (5.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from pandas->learnedSpectrum==0.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from pandas->learnedSpectrum==0.1.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from pandas->learnedSpectrum==0.1.0) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from requests->learnedSpectrum==0.1.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from requests->learnedSpectrum==0.1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from requests->learnedSpectrum==0.1.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from requests->learnedSpectrum==0.1.0) (2024.8.30)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from scikit-learn->learnedSpectrum==0.1.0) (3.5.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from timm->learnedSpectrum==0.1.0) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from timm->learnedSpectrum==0.1.0) (0.26.3)\n",
      "Requirement already satisfied: safetensors in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from timm->learnedSpectrum==0.1.0) (0.4.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torchvision->learnedSpectrum==0.1.0) (11.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from tqdm->learnedSpectrum==0.1.0) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from transformers->learnedSpectrum==0.1.0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from transformers->learnedSpectrum==0.1.0) (0.20.3)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (5.29.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (6.1.0)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (2.19.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (1.3.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (65.5.0)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb->learnedSpectrum==0.1.0) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->learnedSpectrum==0.1.0) (4.0.11)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from jinja2->torch>=2.0->learnedSpectrum==0.1.0) (3.0.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->learnedSpectrum==0.1.0) (5.0.1)\n",
      "Building wheels for collected packages: learnedSpectrum\n",
      "  Building editable for learnedSpectrum (pyproject.toml): started\n",
      "  Building editable for learnedSpectrum (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for learnedSpectrum: filename=learnedSpectrum-0.1.0-0.editable-py3-none-any.whl size=7651 sha256=7578107ea23b08901d895164f60f2bb73a23fa6d94259fc94821a48ddd1145ce\n",
      "  Stored in directory: C:\\Users\\twarn\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-4axuhl_n\\wheels\\df\\e2\\01\\25b890ddbee843adacdabb258984995d70b3d4b4901a7c5b3a\n",
      "Successfully built learnedSpectrum\n",
      "Installing collected packages: learnedSpectrum\n",
      "  Attempting uninstall: learnedSpectrum\n",
      "    Found existing installation: learnedSpectrum 0.1.0\n",
      "    Uninstalling learnedSpectrum-0.1.0:\n",
      "      Successfully uninstalled learnedSpectrum-0.1.0\n",
      "Successfully installed learnedSpectrum-0.1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Install package in editable mode if not already installed\n",
    "!pip install -e {project_root}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\twarn\\Repositories\\learnedSpectrum\\learnedSpectrum\\train.py:178: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "from learnedSpectrum.config import Config, DataConfig\n",
    "from learnedSpectrum.data import DatasetManager, create_dataloaders\n",
    "from learnedSpectrum.train import VisionTransformerModel, train_one_epoch, evaluate\n",
    "from learnedSpectrum.visualization import VisualizationManager\n",
    "from learnedSpectrum.utils import (\n",
    "    seed_everything,\n",
    "    get_optimizer,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    save_checkpoint,\n",
    "    load_checkpoint,\n",
    "    calculate_metrics,\n",
    "    verify_model_devices\n",
    ")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: tawarner (tawarner-usc). Use `wandb login --relogin` to force relogin\n",
      "wandb: WARNING Path C:\\Users\\twarn\\Repositories\\learnedSpectrum\\wandb\\wandb\\ wasn't writable, using system temp directory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\twarn\\AppData\\Local\\Temp\\wandb\\run-20241204_185917-njppqfzu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tawarner-usc/fmri-learning-stages/runs/njppqfzu' target=\"_blank\">usual-surf-218</a></strong> to <a href='https://wandb.ai/tawarner-usc/fmri-learning-stages' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tawarner-usc/fmri-learning-stages' target=\"_blank\">https://wandb.ai/tawarner-usc/fmri-learning-stages</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tawarner-usc/fmri-learning-stages/runs/njppqfzu' target=\"_blank\">https://wandb.ai/tawarner-usc/fmri-learning-stages/runs/njppqfzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize configurations\n",
    "config = Config()\n",
    "data_config = DataConfig()\n",
    "\n",
    "os.makedirs(config.CKPT_DIR, exist_ok=True)\n",
    "\n",
    "# Set up visualization\n",
    "viz = VisualizationManager(save_dir=Path(config.ROOT) / \"visualizations\")\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(\n",
    "    project='fmri-learning-stages',\n",
    "    config=vars(config),\n",
    "    dir=Path(config.ROOT) / \"wandb\"\n",
    ")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Preparing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13199525dacb43b286e7f679ae623578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading datasets:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effab6c9acc8414ab2ed479fba76eb15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validating:   0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18a982cb042445090474a39703f4ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessing:   0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8231a825e94657b98d91e82e9aa43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validating pairs:   0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:learnedSpectrum.data:total valid: 264\n",
      "INFO:__main__:Dataset sizes - Train: 184, Val: 39, Test: 41\n"
     ]
    }
   ],
   "source": [
    "# Initialize dataset manager\n",
    "dataset_manager = DatasetManager(config, data_config)\n",
    "\n",
    "# Prepare datasets\n",
    "logger.info(\"Preparing datasets...\")\n",
    "train_ds, val_ds, test_ds = dataset_manager.prepare_datasets()\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    train_ds, val_ds, test_ds, config  # Use correct variable names\n",
    ")\n",
    "\n",
    "logger.info(f\"Dataset sizes - Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and visualize a sample\n",
    "sample_volume, sample_label = train_ds[0]\n",
    "viz.plot_brain_slice(\n",
    "    volume=sample_volume.numpy(),\n",
    "    time_idx=0,  # View first timepoint\n",
    "    title=f'Sample Brain Slice (Learning Stage: {sample_label})',\n",
    "    save_name='sample_slice'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\twarn\\Repositories\\learnedSpectrum\\learnedSpectrum\\train.py:165: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3687.)\n",
      "  pe[:, 0::2] = torch.sin(pos * omega.T)\n",
      "INFO:learnedSpectrum.utils:model on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = VisionTransformerModel(config)\n",
    "verify_model_devices(model)\n",
    "\n",
    "# Setup training components\n",
    "optimizer = get_optimizer(model, config)\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=config.USE_AMP)\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=config.WARMUP_EPOCHS * len(train_loader),\n",
    "    num_training_steps=config.NUM_EPOCHS * len(train_loader)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loader lens: train=46, val=39\n",
      "batch peek: torch.Size([4, 64, 64, 8, 4860])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "Epoch 1/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_0.pth\n",
      "INFO:__main__:Epoch 1 - Train Loss: 1.3291, Train Acc: 0.0217, Val Loss: 1.3320, Val Acc: 0.0513\n",
      "INFO:__main__:\n",
      "Epoch 2/20\n",
      "INFO:__main__:Epoch 2 - Train Loss: 1.3383, Train Acc: 0.0272, Val Loss: 1.3393, Val Acc: 0.0256\n",
      "INFO:__main__:\n",
      "Epoch 3/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_2.pth\n",
      "INFO:__main__:Epoch 3 - Train Loss: 1.2473, Train Acc: 0.3152, Val Loss: 1.2466, Val Acc: 0.2564\n",
      "INFO:__main__:\n",
      "Epoch 4/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_3.pth\n",
      "INFO:__main__:Epoch 4 - Train Loss: 1.2434, Train Acc: 0.2826, Val Loss: 1.2435, Val Acc: 0.2564\n",
      "INFO:__main__:\n",
      "Epoch 5/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_4.pth\n",
      "INFO:__main__:Epoch 5 - Train Loss: 1.1694, Train Acc: 0.7011, Val Loss: 1.1688, Val Acc: 0.6923\n",
      "INFO:__main__:\n",
      "Epoch 6/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_5.pth\n",
      "INFO:__main__:Epoch 6 - Train Loss: 1.1179, Train Acc: 0.8424, Val Loss: 1.1165, Val Acc: 0.7949\n",
      "INFO:__main__:\n",
      "Epoch 7/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_6.pth\n",
      "INFO:__main__:Epoch 7 - Train Loss: 0.9960, Train Acc: 1.0000, Val Loss: 0.9937, Val Acc: 0.9744\n",
      "INFO:__main__:\n",
      "Epoch 8/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_7.pth\n",
      "INFO:__main__:Epoch 8 - Train Loss: 0.9038, Train Acc: 1.0000, Val Loss: 0.8979, Val Acc: 1.0000\n",
      "INFO:__main__:\n",
      "Epoch 9/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_8.pth\n",
      "INFO:__main__:Epoch 9 - Train Loss: 0.8119, Train Acc: 1.0000, Val Loss: 0.8067, Val Acc: 1.0000\n",
      "INFO:__main__:\n",
      "Epoch 10/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_9.pth\n",
      "INFO:__main__:Epoch 10 - Train Loss: 0.7029, Train Acc: 1.0000, Val Loss: 0.6952, Val Acc: 1.0000\n",
      "INFO:__main__:\n",
      "Epoch 11/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_10.pth\n",
      "INFO:__main__:Epoch 11 - Train Loss: 0.5972, Train Acc: 1.0000, Val Loss: 0.5873, Val Acc: 1.0000\n",
      "INFO:__main__:\n",
      "Epoch 12/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_11.pth\n",
      "INFO:__main__:Epoch 12 - Train Loss: 0.5144, Train Acc: 1.0000, Val Loss: 0.5057, Val Acc: 1.0000\n",
      "INFO:__main__:\n",
      "Epoch 13/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_12.pth\n",
      "INFO:__main__:Epoch 13 - Train Loss: 0.4135, Train Acc: 1.0000, Val Loss: 0.4069, Val Acc: 1.0000\n",
      "INFO:__main__:\n",
      "Epoch 14/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_13.pth\n",
      "INFO:__main__:Epoch 14 - Train Loss: 0.3272, Train Acc: 1.0000, Val Loss: 0.3181, Val Acc: 1.0000\n",
      "INFO:__main__:\n",
      "Epoch 15/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_14.pth\n",
      "INFO:__main__:Epoch 15 - Train Loss: 0.2584, Train Acc: 1.0000, Val Loss: 0.2464, Val Acc: 1.0000\n",
      "INFO:__main__:\n",
      "Epoch 16/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_15.pth\n",
      "INFO:__main__:Epoch 16 - Train Loss: 0.2068, Train Acc: 1.0000, Val Loss: 0.2070, Val Acc: 1.0000\n",
      "INFO:__main__:\n",
      "Epoch 17/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_16.pth\n",
      "INFO:__main__:Epoch 17 - Train Loss: 0.1608, Train Acc: 1.0000, Val Loss: 0.1629, Val Acc: 1.0000\n",
      "INFO:__main__:\n",
      "Epoch 18/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_17.pth\n",
      "INFO:__main__:Epoch 18 - Train Loss: 0.0997, Train Acc: 1.0000, Val Loss: 0.0952, Val Acc: 1.0000\n",
      "INFO:__main__:\n",
      "Epoch 19/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_18.pth\n",
      "INFO:__main__:Epoch 19 - Train Loss: 0.0708, Train Acc: 1.0000, Val Loss: 0.0661, Val Acc: 1.0000\n",
      "INFO:__main__:\n",
      "Epoch 20/20\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\learnedSpectrum\\notebooks\\models\\best_model_epoch_19.pth\n",
      "INFO:__main__:Epoch 20 - Train Loss: 0.0480, Train Acc: 1.0000, Val Loss: 0.0471, Val Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Training history\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(f\"loader lens: train={len(train_loader)}, val={len(val_loader)}\")\n",
    "\n",
    "# Safe batch peek without timeout\n",
    "try:\n",
    "    batch = next(iter(train_loader))\n",
    "    print(f\"batch peek: {batch[0].shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Batch peek failed (this is ok): {str(e)}\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(config.NUM_EPOCHS):\n",
    "    logger.info(f\"\\nEpoch {epoch + 1}/{config.NUM_EPOCHS}\")\n",
    "    \n",
    "    # Training phase\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, scaler, config)\n",
    "    train_loss, train_metrics = evaluate(model, train_loader, config)\n",
    "    \n",
    "    # Validation phase\n",
    "    val_loss, val_metrics = evaluate(model, val_loader, config)\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_metrics['accuracy'])\n",
    "    history['val_acc'].append(val_metrics['accuracy'])\n",
    "    \n",
    "    # Plot training progress\n",
    "    viz.plot_training_history(history, save_name=f'training_history_epoch_{epoch}')\n",
    "    \n",
    "    # Log to wandb\n",
    "    viz.log_to_wandb({\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'train_metrics': train_metrics,\n",
    "        'val_metrics': val_metrics,\n",
    "        'learning_rate': optimizer.param_groups[0]['lr']\n",
    "    }, epoch)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        save_checkpoint(\n",
    "            model, optimizer, epoch, val_loss, config,\n",
    "            filename=f\"best_model_epoch_{epoch}.pth\"\n",
    "        )\n",
    "        \n",
    "    logger.info(\n",
    "        f\"Epoch {epoch + 1} - \"\n",
    "        f\"Train Loss: {train_loss:.4f}, \"\n",
    "        f\"Train Acc: {train_metrics['accuracy']:.4f}, \"\n",
    "        f\"Val Loss: {val_loss:.4f}, \"\n",
    "        f\"Val Acc: {val_metrics['accuracy']:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ckpt fail: [Errno 2] No such file or directory: 'C:\\\\Users\\\\twarn\\\\Repositories\\\\learnedSpectrum\\\\notebooks\\\\models\\\\best_model.pth', continuing w/ fresh model\n",
      "INFO:__main__:\n",
      "Test Results - Loss: 0.0457, Accuracy: 1.0000, AUC: nan\n"
     ]
    }
   ],
   "source": [
    "# Load best model\n",
    "best_model_path = Path(config.CKPT_DIR) / \"best_model.pth\"\n",
    "model, _, _ = load_checkpoint(model, None, best_model_path)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_metrics = evaluate(model, test_loader, config)\n",
    "logger.info(f\"\\nTest Results - Loss: {test_loss:.4f}, Accuracy: {test_metrics['accuracy']:.4f}, AUC: {test_metrics['auc']:.4f}\")\n",
    "\n",
    "# Get predictions for visualization\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "all_probs = np.array(all_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:learnedSpectrum.visualization:degenerate predictions detected\n",
      "WARNING:learnedSpectrum.visualization:insufficient classes for roc\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VisionTransformerModel' object has no attribute 'get_attention_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(test_loader))[\u001b[38;5;241m0\u001b[39m][:\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 19\u001b[0m     weights \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_attention_weights\u001b[49m(x)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# [layers, heads, seq, seq] -> [seq, seq] for viz\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     avg_weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m])  \n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1933\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'VisionTransformerModel' object has no attribute 'get_attention_weights'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# conf matrix + roc\n",
    "viz.plot_confusion_matrix(\n",
    "    y_true=all_labels,\n",
    "    y_pred=all_preds,\n",
    "    classes=['Early', 'Middle', 'Late', 'Mastery'],\n",
    "    save_name='confusion_matrix'\n",
    ")\n",
    "\n",
    "viz.plot_roc_curves(\n",
    "    y_true=all_labels,\n",
    "    y_scores=all_probs,\n",
    "    classes=['Early', 'Middle', 'Late', 'Mastery'],\n",
    "    save_name='roc_curves'\n",
    ")\n",
    "\n",
    "# attn viz w/ proper extraction\n",
    "x = next(iter(test_loader))[0][:1].to(device)\n",
    "with torch.no_grad():\n",
    "    weights = model.get_attention_weights(x)\n",
    "    # [layers, heads, seq, seq] -> [seq, seq] for viz\n",
    "    avg_weights = weights.mean(dim=[0,1])  \n",
    "\n",
    "viz.plot_attention_map(\n",
    "    attention_weights=avg_weights.cpu(),\n",
    "    volume_shape=config.VOLUME_SIZE,\n",
    "    save_name='attention_map'\n",
    ")\n",
    "\n",
    "# wandb artifacts\n",
    "wandb.log({\n",
    "    'final_test_loss': test_loss,\n",
    "    'final_test_accuracy': test_metrics['accuracy'], \n",
    "    'final_test_auc': test_metrics['auc'],\n",
    "    'visualizations': {\n",
    "        'confusion_matrix': wandb.Image(str(viz.save_dir / 'confusion_matrix.png')),\n",
    "        'roc_curves': wandb.Image(str(viz.save_dir / 'roc_curves.png')),\n",
    "        'attention_map': wandb.Image(str(viz.save_dir / 'attention_map.png'))\n",
    "    }\n",
    "})\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
