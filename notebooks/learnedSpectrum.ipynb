{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# fMRI Learning Stage Classification with Vision Transformers\n",
       "\n",
       "This notebook demonstrates the use of Vision Transformers for classifying different stages of learning from fMRI data."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Setup and Imports"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import sys\n",
       "from pathlib import Path\n",
       "\n",
       "# Add project root to path\n",
       "project_root = Path().absolute().parent\n",
       "sys.path.append(str(project_root))\n",
       "\n",
       "# Install package in editable mode if not already installed\n",
       "!pip install -e {project_root}"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import logging\n",
       "import torch\n",
       "import wandb\n",
       "import numpy as np\n",
       "from torch.cuda.amp import GradScaler\n",
       "\n",
       "from learnedSpectrum.config import Config, DataConfig\n",
       "from learnedSpectrum.data import DatasetManager, create_dataloaders\n",
       "from learnedSpectrum.scripts.train import VisionTransformerModel, train_one_epoch, evaluate\n",
       "from learnedSpectrum.scripts.visualization import VisualizationManager\n",
       "from learnedSpectrum.utils import (\n",
       "    seed_everything,\n",
       "    get_optimizer,\n",
       "    get_cosine_schedule_with_warmup,\n",
       "    verify_model_devices\n",
       ")\n",
       "\n",
       "logging.basicConfig(level=logging.INFO)\n",
       "logger = logging.getLogger(__name__)\n",
       "\n",
       "# Set random seed for reproducibility\n",
       "seed_everything(42)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Configuration"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Initialize configurations\n",
       "config = Config()\n",
       "data_config = DataConfig()\n",
       "\n",
       "# Set up visualization\n",
       "viz = VisualizationManager(save_dir=Path(config.ROOT) / \"visualizations\")\n",
       "\n",
       "# Initialize wandb\n",
       "wandb.init(\n",
       "    project='fmri-learning-stages',\n",
       "    config=vars(config),\n",
       "    dir=Path(config.ROOT) / \"wandb\"\n",
       ")\n",
       "\n",
       "# Set device\n",
       "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
       "logger.info(f\"Using device: {device}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Data Preparation"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Initialize dataset manager\n",
       "dataset_manager = DatasetManager(config, data_config)\n",
       "\n",
       "# Prepare datasets\n",
       "logger.info(\"Preparing datasets...\")\n",
       "train_dataset, val_dataset, test_dataset = dataset_manager.prepare_datasets()\n",
       "\n",
       "# Create dataloaders\n",
       "train_loader, val_loader, test_loader = create_dataloaders(\n",
       "    train_dataset, val_dataset, test_dataset, config\n",
       ")\n",
       "\n",
       "logger.info(f\"Dataset sizes - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Visualize Sample Data"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Get and visualize a sample\n",
       "sample_volume, sample_label = train_dataset[0]\n",
       "viz.plot_brain_slice(\n",
       "    volume=sample_volume.numpy(),\n",
       "    title=f'Sample Brain Slice (Learning Stage: {sample_label})',\n",
       "    save_name='sample_slice'\n",
       ")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Model Setup"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Initialize model\n",
       "model = VisionTransformerModel(config).to(device)\n",
       "verify_model_devices(model)\n",
       "\n",
       "# Setup training components\n",
       "optimizer = get_optimizer(model, config)\n",
       "scaler = GradScaler(enabled=config.USE_AMP)\n",
       "scheduler = get_cosine_schedule_with_warmup(\n",
       "    optimizer,\n",
       "    num_warmup_steps=config.WARMUP_EPOCHS * len(train_loader),\n",
       "    num_training_steps=config.NUM_EPOCHS * len(train_loader)\n",
       ")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Training Loop"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Training history\n",
       "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
       "best_val_loss = float('inf')\n",
       "\n",
       "# Training loop\n",
       "for epoch in range(config.NUM_EPOCHS):\n",
       "    logger.info(f\"\\nEpoch {epoch + 1}/{config.NUM_EPOCHS}\")\n",
       "    \n",
       "    # Training phase\n",
       "    train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, scaler, config)\n",
       "    train_loss, train_metrics = evaluate(model, train_loader, config)\n",
       "    \n",
       "    # Validation phase\n",
       "    val_loss, val_metrics = evaluate(model, val_loader, config)\n",
       "    \n",
       "    # Update history\n",
       "    history['train_loss'].append(train_loss)\n",
       "    history['val_loss'].append(val_loss)\n",
       "    history['train_acc'].append(train_metrics['accuracy'])\n",
       "    history['val_acc'].append(val_metrics['accuracy'])\n",
       "    \n",
       "    # Plot training progress\n",
       "    viz.plot_training_history(history, save_name=f'training_history_epoch_{epoch}')\n",
       "    \n",
       "    # Log to wandb\n",
       "    viz.log_to_wandb({\n",
       "        'train_loss': train_loss,\n",
       "        'val_loss': val_loss,\n",
       "        'train_metrics': train_metrics,\n",
       "        'val_metrics': val_metrics,\n",
       "        'learning_rate': optimizer.param_groups[0]['lr']\n",
       "    }, epoch)\n",
       "    \n",
       "    # Save best model\n",
       "    if val_loss < best_val_loss:\n",
       "        best_val_loss = val_loss\n",
       "        save_checkpoint(\n",
       "            model, optimizer, epoch, val_loss, config,\n",
       "            filename=f\"best_model_epoch_{epoch}.pth\"\n",
       "        )\n",
       "        \n",
       "    logger.info(\n",
       "        f\"Epoch {epoch + 1} - \"\n",
       "        f\"Train Loss: {train_loss:.4f}, \"\n",
       "        f\"Train Acc: {train_metrics['accuracy']:.4f}, \"\n",
       "        f\"Val Loss: {val_loss:.4f}, \"\n",
       "        f\"Val Acc: {val_metrics['accuracy']:.4f}\"\n",
       "    )"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Final Evaluation"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Load best model\n",
       "best_model_path = Path(config.CKPT_DIR) / \"best_model.pth\"\n",
       "model, _, _ = load_checkpoint(model, None, best_model_path)\n",
       "\n",
       "# Evaluate on test set\n",
       "test_loss, test_metrics = evaluate(model, test_loader, config)\n",
       "logger.info(f\"\\nTest Results - Loss: {test_loss:.4f}, Accuracy: {test_metrics['accuracy']:.4f}, AUC: {test_metrics['auc']:.4f}\")\n",
       "\n",
       "# Get predictions for visualization\n",
       "all_preds = []\n",
       "all_labels = []\n",
       "all_probs = []\n",
       "\n",
       "model.eval()\n",
       "with torch.no_grad():\n",
       "    for inputs, labels in test_loader:\n",
       "        inputs = inputs.to(device)\n",
       "        outputs = model(inputs)\n",
       "        probs = torch.softmax(outputs, dim=1)\n",
       "        preds = torch.argmax(outputs, dim=1)\n",
       "        \n",
       "        all_preds.extend(preds.cpu().numpy())\n",
       "        all_labels.extend(labels.numpy())\n",
       "        all_probs.extend(probs.cpu().numpy())\n",
       "\n",
       "all_preds = np.array(all_preds)\n",
       "all_labels = np.array(all_labels)\n",
       "all_probs = np.array(all_probs)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Results Visualization"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Plot confusion matrix\n",
       "viz.plot_confusion_matrix(\n",
       "    y_true=all_labels,\n",
       "    y_pred=all_preds,\n",
       "    classes=['Early', 'Middle', 'Late', 'Mastery'],\n",
       "    save_name='confusion_matrix'\n",
       ")\n",
       "\n",
       "# Plot ROC curves\n",
       "viz.plot_roc_curves(\n",
       "    y_true=all_labels,\n",
       "    y_scores=all_probs,\n",
       "    classes=['Early', 'Middle', 'Late', 'Mastery'],\n",
       "    save_name='roc_curves'\n",
       ")\n",
       "\n",
       "# Visualize attention maps for a sample\n",
       "sample_input = next(iter(test_loader))[0][:1].to(device)\n",
       "with torch.no_grad():\n",
       "    attention_weights = model.vit.get_attention_weights(sample_input)\n",
       "\n",
       "viz.plot_attention_map(\n",
       "    attention_weights=attention_weights[0].cpu(),  # First head's attention\n",
       "    volume_shape=config.VOLUME_SIZE,\n",
       "    save_name='attention_map'\n",
       ")\n",
       "\n",
       "# Save final results to wandb\n",
       "wandb.log({\n",
       "    'final_test_loss': test_loss,\n",
       "    'final_test_accuracy': test_metrics['accuracy'],\n",
       "    'final_test_auc': test_metrics['auc'],\n",
       "    'confusion_matrix': wandb.Image(str(viz.save_dir / 'confusion_matrix.png')),\n",
       "    'roc_curves': wandb.Image(str(viz.save_dir / 'roc_curves.png')),\n",
       "    'attention_map': wandb.Image(str(viz.save_dir / 'attention_map.png'))\n",
       "})\n",
       "\n",
       "wandb.finish()"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }