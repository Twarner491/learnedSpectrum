{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fMRI Learning Stage Classification with Vision Transformers\n",
    "\n",
    "This notebook demonstrates the use of Vision Transformers for classifying different stages of learning from fMRI data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/twarn/Repositories/learnedSpectrum\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (0.20.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (2.1.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (2.2.3)\n",
      "Requirement already satisfied: nibabel in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (5.3.2)\n",
      "Requirement already satisfied: nilearn in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (0.11.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (1.5.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (4.46.3)\n",
      "Requirement already satisfied: wandb in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (0.18.7)\n",
      "Requirement already satisfied: lru-dict in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: pywavelets in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (1.7.0)\n",
      "Requirement already satisfied: einops in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (0.8.0)\n",
      "Requirement already satisfied: timm in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (1.0.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (4.67.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (1.14.1)\n",
      "Requirement already satisfied: requests in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from learnedSpectrum==0.1.0) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torch>=2.0->learnedSpectrum==0.1.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torch>=2.0->learnedSpectrum==0.1.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torch>=2.0->learnedSpectrum==0.1.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torch>=2.0->learnedSpectrum==0.1.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torch>=2.0->learnedSpectrum==0.1.0) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torch>=2.0->learnedSpectrum==0.1.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->learnedSpectrum==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-resources>=5.12 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from nibabel->learnedSpectrum==0.1.0) (6.4.5)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from nibabel->learnedSpectrum==0.1.0) (24.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from nilearn->learnedSpectrum==0.1.0) (1.4.2)\n",
      "Requirement already satisfied: lxml in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from nilearn->learnedSpectrum==0.1.0) (5.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from pandas->learnedSpectrum==0.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from pandas->learnedSpectrum==0.1.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from pandas->learnedSpectrum==0.1.0) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from requests->learnedSpectrum==0.1.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from requests->learnedSpectrum==0.1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from requests->learnedSpectrum==0.1.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from requests->learnedSpectrum==0.1.0) (2024.8.30)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from scikit-learn->learnedSpectrum==0.1.0) (3.5.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from timm->learnedSpectrum==0.1.0) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from timm->learnedSpectrum==0.1.0) (0.26.3)\n",
      "Requirement already satisfied: safetensors in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from timm->learnedSpectrum==0.1.0) (0.4.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from torchvision->learnedSpectrum==0.1.0) (11.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from tqdm->learnedSpectrum==0.1.0) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from transformers->learnedSpectrum==0.1.0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from transformers->learnedSpectrum==0.1.0) (0.20.3)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (5.29.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (6.1.0)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (2.19.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (1.3.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from wandb->learnedSpectrum==0.1.0) (65.5.0)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb->learnedSpectrum==0.1.0) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->learnedSpectrum==0.1.0) (4.0.11)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from jinja2->torch>=2.0->learnedSpectrum==0.1.0) (3.0.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\twarn\\repositories\\learnedspectrum\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->learnedSpectrum==0.1.0) (5.0.1)\n",
      "Building wheels for collected packages: learnedSpectrum\n",
      "  Building editable for learnedSpectrum (pyproject.toml): started\n",
      "  Building editable for learnedSpectrum (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for learnedSpectrum: filename=learnedSpectrum-0.1.0-0.editable-py3-none-any.whl size=7813 sha256=7b75f72096216dc6ebb837fd6b7fbb6bd99cae136254582516a5c0706855f644\n",
      "  Stored in directory: C:\\Users\\twarn\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-5qtieg19\\wheels\\df\\e2\\01\\25b890ddbee843adacdabb258984995d70b3d4b4901a7c5b3a\n",
      "Successfully built learnedSpectrum\n",
      "Installing collected packages: learnedSpectrum\n",
      "  Attempting uninstall: learnedSpectrum\n",
      "    Found existing installation: learnedSpectrum 0.1.0\n",
      "    Uninstalling learnedSpectrum-0.1.0:\n",
      "      Successfully uninstalled learnedSpectrum-0.1.0\n",
      "Successfully installed learnedSpectrum-0.1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Install package in editable mode if not already installed\n",
    "!pip install -e {project_root}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "from learnedSpectrum.config import Config, DataConfig\n",
    "from learnedSpectrum.data import DatasetManager, create_dataloaders\n",
    "from learnedSpectrum.train import VisionTransformerModel, train_one_epoch, evaluate\n",
    "from learnedSpectrum.visualization import VisualizationManager\n",
    "from learnedSpectrum.utils import (\n",
    "    seed_everything,\n",
    "    get_optimizer,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    save_checkpoint,\n",
    "    load_checkpoint,\n",
    "    calculate_metrics,\n",
    "    verify_model_devices\n",
    ")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: tawarner (tawarner-usc). Use `wandb login --relogin` to force relogin\n",
      "wandb: WARNING Path C:\\Users\\twarn\\Repositories\\wandb\\wandb\\ wasn't writable, using system temp directory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\twarn\\AppData\\Local\\Temp\\wandb\\run-20241203_000617-7c8uxbe2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tawarner-usc/fmri-learning-stages/runs/7c8uxbe2' target=\"_blank\">mild-dream-67</a></strong> to <a href='https://wandb.ai/tawarner-usc/fmri-learning-stages' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tawarner-usc/fmri-learning-stages' target=\"_blank\">https://wandb.ai/tawarner-usc/fmri-learning-stages</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tawarner-usc/fmri-learning-stages/runs/7c8uxbe2' target=\"_blank\">https://wandb.ai/tawarner-usc/fmri-learning-stages/runs/7c8uxbe2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize configurations\n",
    "config = Config()\n",
    "data_config = DataConfig()\n",
    "\n",
    "# Set up visualization\n",
    "viz = VisualizationManager(save_dir=Path(config.ROOT) / \"visualizations\")\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(\n",
    "    project='fmri-learning-stages',\n",
    "    config=vars(config),\n",
    "    dir=Path(config.ROOT) / \"wandb\"\n",
    ")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Preparing datasets...\n",
      "INFO:learnedSpectrum.data:splits: train=238, val=29, test=31\n",
      "INFO:__main__:Dataset sizes - Train: 238, Val: 29, Test: 31\n"
     ]
    }
   ],
   "source": [
    "# Initialize dataset manager\n",
    "dataset_manager = DatasetManager(config, data_config)\n",
    "\n",
    "# Prepare datasets\n",
    "logger.info(\"Preparing datasets...\")\n",
    "train_dataset, val_dataset, test_dataset = dataset_manager.prepare_datasets()\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    train_dataset, val_dataset, test_dataset, config\n",
    ")\n",
    "\n",
    "logger.info(f\"Dataset sizes - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and visualize a sample\n",
    "sample_volume, sample_label = train_dataset[0]\n",
    "viz.plot_brain_slice(\n",
    "    volume=sample_volume.numpy(),\n",
    "    title=f'Sample Brain Slice (Learning Stage: {sample_label})',\n",
    "    save_name='sample_slice'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:learnedSpectrum.utils:model on: cuda:0\n",
      "C:\\Users\\twarn\\AppData\\Local\\Temp\\ipykernel_36984\\1377333977.py:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=config.USE_AMP)\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = VisionTransformerModel(config)\n",
    "verify_model_devices(model)\n",
    "\n",
    "# Setup training components\n",
    "optimizer = get_optimizer(model, config)\n",
    "scaler = GradScaler(enabled=config.USE_AMP)\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=config.WARMUP_EPOCHS * len(train_loader),\n",
    "    num_training_steps=config.NUM_EPOCHS * len(train_loader)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loader lens: train=60, val=8\n",
      "batch peek: torch.Size([4, 64, 64, 30, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "Epoch 1/30\n",
      "INFO:learnedSpectrum.utils:checkpoint: C:\\Users\\twarn\\Repositories\\models\\checkpoints\\best_model_epoch_0.pth\n",
      "INFO:__main__:Epoch 1 - Train Loss: 0.1990, Train Acc: 1.0000, Val Loss: 0.2063, Val Acc: 1.0000\n",
      "INFO:__main__:\n",
      "Epoch 2/30\n",
      "INFO:__main__:Epoch 2 - Train Loss: 0.2647, Train Acc: 1.0000, Val Loss: 0.2666, Val Acc: 1.0000\n",
      "INFO:__main__:\n",
      "Epoch 3/30\n"
     ]
    }
   ],
   "source": [
    "# Training history\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(f\"loader lens: train={len(train_loader)}, val={len(val_loader)}\")\n",
    "print(f\"batch peek: {next(iter(train_loader))[0].shape}\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(config.NUM_EPOCHS):\n",
    "    logger.info(f\"\\nEpoch {epoch + 1}/{config.NUM_EPOCHS}\")\n",
    "    \n",
    "    # Training phase\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, scaler, config)\n",
    "    train_loss, train_metrics = evaluate(model, train_loader, config)\n",
    "    \n",
    "    # Validation phase\n",
    "    val_loss, val_metrics = evaluate(model, val_loader, config)\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_metrics['accuracy'])\n",
    "    history['val_acc'].append(val_metrics['accuracy'])\n",
    "    \n",
    "    # Plot training progress\n",
    "    viz.plot_training_history(history, save_name=f'training_history_epoch_{epoch}')\n",
    "    \n",
    "    # Log to wandb\n",
    "    viz.log_to_wandb({\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'train_metrics': train_metrics,\n",
    "        'val_metrics': val_metrics,\n",
    "        'learning_rate': optimizer.param_groups[0]['lr']\n",
    "    }, epoch)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        save_checkpoint(\n",
    "            model, optimizer, epoch, val_loss, config,\n",
    "            filename=f\"best_model_epoch_{epoch}.pth\"\n",
    "        )\n",
    "        \n",
    "    logger.info(\n",
    "        f\"Epoch {epoch + 1} - \"\n",
    "        f\"Train Loss: {train_loss:.4f}, \"\n",
    "        f\"Train Acc: {train_metrics['accuracy']:.4f}, \"\n",
    "        f\"Val Loss: {val_loss:.4f}, \"\n",
    "        f\"Val Acc: {val_metrics['accuracy']:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_path = Path(config.CKPT_DIR) / \"best_model.pth\"\n",
    "model, _, _ = load_checkpoint(model, None, best_model_path)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_metrics = evaluate(model, test_loader, config)\n",
    "logger.info(f\"\\nTest Results - Loss: {test_loss:.4f}, Accuracy: {test_metrics['accuracy']:.4f}, AUC: {test_metrics['auc']:.4f}\")\n",
    "\n",
    "# Get predictions for visualization\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "all_probs = np.array(all_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "viz.plot_confusion_matrix(\n",
    "    y_true=all_labels,\n",
    "    y_pred=all_preds,\n",
    "    classes=['Early', 'Middle', 'Late', 'Mastery'],\n",
    "    save_name='confusion_matrix'\n",
    ")\n",
    "\n",
    "# Plot ROC curves\n",
    "viz.plot_roc_curves(\n",
    "    y_true=all_labels,\n",
    "    y_scores=all_probs,\n",
    "    classes=['Early', 'Middle', 'Late', 'Mastery'],\n",
    "    save_name='roc_curves'\n",
    ")\n",
    "\n",
    "# Visualize attention maps for a sample\n",
    "sample_input = next(iter(test_loader))[0][:1].to(device)\n",
    "with torch.no_grad():\n",
    "    attention_weights = model.vit.get_attention_weights(sample_input)\n",
    "\n",
    "viz.plot_attention_map(\n",
    "    attention_weights=attention_weights[0].cpu(),  # First head's attention\n",
    "    volume_shape=config.VOLUME_SIZE,\n",
    "    save_name='attention_map'\n",
    ")\n",
    "\n",
    "# Save final results to wandb\n",
    "wandb.log({\n",
    "    'final_test_loss': test_loss,\n",
    "    'final_test_accuracy': test_metrics['accuracy'],\n",
    "    'final_test_auc': test_metrics['auc'],\n",
    "    'confusion_matrix': wandb.Image(str(viz.save_dir / 'confusion_matrix.png')),\n",
    "    'roc_curves': wandb.Image(str(viz.save_dir / 'roc_curves.png')),\n",
    "    'attention_map': wandb.Image(str(viz.save_dir / 'attention_map.png'))\n",
    "})\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
